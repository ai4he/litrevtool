% BibTeX entries generated by LitRevTool
% ======================================================================

@article{SolvingUnknown,
  title = {Solving quantitative reasoning problems with language models},
  author = {A Lewkowycz, A Andreassen…},
  journal = {Advances in neural …, 2022},
  publisher = {proceedings.neurips.cc},
  abstract = {… In particular, large language models have achieved excellent performance across a 
variety … of the MATH prompt for topics that involve mathematical reasoning, and add step-by-step …},
  url = {https://proceedings.neurips.cc/paper_files/paper/2022/hash/18abbeef8cfe9203fdf9053c9c4fe191-Abstract-Conference.html},
  note = {Retrieved from Google Scholar}
}

@article{AutoformalizationUnknown,
  title = {Autoformalization with large language models},
  author = {Y Wu, AQ Jiang, W Li, M Rabe…},
  journal = {Advances in neural …, 2022},
  publisher = {proceedings.neurips.cc},
  abstract = {… fields that automate aspects of mathematical reasoning, such as automated … Recent 
advances in large language models [8… with large language models. To our surprise, we find that …},
  url = {https://proceedings.neurips.cc/paper_files/paper/2022/hash/d0c6bc641a56bebee9d985b937307367-Abstract-Conference.html},
  note = {Retrieved from Google Scholar}
}

@article{NaturalproverUnknown,
  title = {Naturalprover: Grounded mathematical proof generation with language models},
  author = {S Welleck, J Liu, X Lu, H Hajishirzi…},
  journal = {Advances in Neural …, 2022},
  publisher = {proceedings.neurips.cc},
  abstract = {… analogous to recent work on language modeling for formal theorem proving [32], where 
current models are typically limited to chaining 2 or 3 non-trivial steps of mathematical reasoning…},
  url = {https://proceedings.neurips.cc/paper_files/paper/2022/hash/1fc548a8243ad06616eee731e0572927-Abstract-Conference.html},
  note = {Retrieved from Google Scholar}
}

@article{LeastUnknown,
  title = {Least-to-most prompting enables complex reasoning in large language models},
  author = {D Zhou, N Schärli, L Hou, J Wei, N Scales…},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {arxiv.org},
  abstract = {… Our empirical findings, which encompass symbolic manipulation, compositional generalization, 
and mathematical reasoning, reveal that least-to-most prompting significantly surpasses …},
  url = {https://arxiv.org/abs/2205.10625},
  note = {Retrieved from Google Scholar}
}

@article{LilaUnknown,
  title = {Lila: A unified benchmark for mathematical reasoning},
  author = {S Mishra, M Finlayson, P Lu, L Tang, S Welleck…},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {arxiv.org},
  abstract = {… of much larger models (≈175B), to better understand the performance of the smaller trained 
models (≈2.7B) and to provide a benchmark for evaluating other large language models. …},
  url = {https://arxiv.org/abs/2210.17517},
  note = {Retrieved from Google Scholar}
}

@article{ProgramUnknown,
  title = {Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks},
  author = {W Chen, X Ma, X Wang, WW Cohen},
  journal = {arXiv preprint arXiv:2211.12588, 2022},
  publisher = {arxiv.org},
  abstract = {… 4.1 Mathematical Reasoning in NLP Mathematical reasoning skills are essential for general-… 
Codet5+: Open code large language models for code understanding and generation. arXiv …},
  url = {https://arxiv.org/abs/2211.12588},
  note = {Retrieved from Google Scholar}
}

@article{StarUnknown,
  title = {Star: Bootstrapping reasoning with reasoning},
  author = {E Zelikman, Y Wu, J Mu…},
  journal = {Advances in Neural …, 2022},
  publisher = {proceedings.neurips.cc},
  abstract = {… for LLMs across diverse tasks including mathematical reasoning, commonsense reasoning, 
… works has emerged exploring the capacity for large language models to perform in-context …},
  url = {https://proceedings.neurips.cc/paper_files/paper/2022/hash/639a9a172c044fbb64175b5fad42e9a5-Abstract-Conference.html},
  note = {Retrieved from Google Scholar}
}

@article{MrklUnknown,
  title = {MRKL Systems: A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning},
  author = {E Karpas, O Abend, Y Belinkov, B Lenz…},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {arxiv.org},
  abstract = {… And mathematical reasoning is just the tip of an iceberg. … Despite all these shortcomings, 
large language models are an essential backbone of any future AI system. So the question is …},
  url = {https://arxiv.org/abs/2205.00445},
  note = {Retrieved from Google Scholar}
}

@article{LanguageUnknown,
  title = {Language models are greedy reasoners: A systematic formal analysis of chain-of-thought},
  author = {A Saparov, H He},
  journal = {arXiv preprint arXiv:2210.01240, 2022},
  publisher = {arxiv.org},
  abstract = {… Large language models (LLMs) have shown remarkable … downstream tasks such as 
mathematical reasoning. However, … of that of general mathematical reasoning. Mathematical …},
  url = {https://arxiv.org/abs/2210.01240},
  note = {Retrieved from Google Scholar}
}

@article{EvaluatingUnknown,
  title = {Evaluating transformer language models on arithmetic operations using number decomposition},
  author = {M Muffo, A Cocco, E Bertino},
  journal = {Proceedings of the Thirteenth …, 2022},
  publisher = {aclanthology.org},
  abstract = {… Abstract In recent years, Large Language Models such as GPT-3 showed remarkable … 
the tasks analysed, suggesting that there is large room for improving mathematical reasoning …},
  url = {https://aclanthology.org/2022.lrec-1.30/},
  note = {Retrieved from Google Scholar}
}

@article{Solving2022,
  title = {Solving quantitative reasoning problems with language models},
  author = {A Lewkowycz, A Andreassen…},
  year = {2022},
  journal = {Advances in neural …, 2022},
  publisher = {proceedings.neurips.cc},
  abstract = {… In particular, large language models have achieved excellent performance across a 
variety … of the MATH prompt for topics that involve mathematical reasoning, and add step-by-step …},
  url = {https://proceedings.neurips.cc/paper_files/paper/2022/hash/18abbeef8cfe9203fdf9053c9c4fe191-Abstract-Conference.html},
  note = {Retrieved from Google Scholar}
}

@article{Autoformalization2022,
  title = {Autoformalization with large language models},
  author = {Y Wu, AQ Jiang, W Li, M Rabe…},
  year = {2022},
  journal = {Advances in neural …, 2022},
  publisher = {proceedings.neurips.cc},
  abstract = {… fields that automate aspects of mathematical reasoning, such as automated … Recent 
advances in large language models [8… with large language models. To our surprise, we find that …},
  url = {https://proceedings.neurips.cc/paper_files/paper/2022/hash/d0c6bc641a56bebee9d985b937307367-Abstract-Conference.html},
  note = {Retrieved from Google Scholar}
}

@article{Naturalprover2022,
  title = {Naturalprover: Grounded mathematical proof generation with language models},
  author = {S Welleck, J Liu, X Lu, H Hajishirzi…},
  year = {2022},
  journal = {Advances in Neural …, 2022},
  publisher = {proceedings.neurips.cc},
  abstract = {… analogous to recent work on language modeling for formal theorem proving [32], where 
current models are typically limited to chaining 2 or 3 non-trivial steps of mathematical reasoning…},
  url = {https://proceedings.neurips.cc/paper_files/paper/2022/hash/1fc548a8243ad06616eee731e0572927-Abstract-Conference.html},
  note = {Retrieved from Google Scholar}
}

@article{Least2022,
  title = {Least-to-most prompting enables complex reasoning in large language models},
  author = {D Zhou, N Schärli, L Hou, J Wei, N Scales…},
  year = {2022},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {arxiv.org},
  abstract = {… Our empirical findings, which encompass symbolic manipulation, compositional generalization, 
and mathematical reasoning, reveal that least-to-most prompting significantly surpasses …},
  url = {https://arxiv.org/abs/2205.10625},
  note = {Retrieved from Google Scholar}
}

@article{Lila2022,
  title = {Lila: A unified benchmark for mathematical reasoning},
  author = {S Mishra, M Finlayson, P Lu, L Tang, S Welleck…},
  year = {2022},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {arxiv.org},
  abstract = {… of much larger models (≈175B), to better understand the performance of the smaller trained 
models (≈2.7B) and to provide a benchmark for evaluating other large language models. …},
  url = {https://arxiv.org/abs/2210.17517},
  note = {Retrieved from Google Scholar}
}

@article{Program2022,
  title = {Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks},
  author = {W Chen, X Ma, X Wang, WW Cohen},
  year = {2022},
  journal = {arXiv preprint arXiv:2211.12588, 2022},
  publisher = {arxiv.org},
  abstract = {… 4.1 Mathematical Reasoning in NLP Mathematical reasoning skills are essential for general-… 
Codet5+: Open code large language models for code understanding and generation. arXiv …},
  url = {https://arxiv.org/abs/2211.12588},
  note = {Retrieved from Google Scholar}
}

@article{Star2022,
  title = {Star: Bootstrapping reasoning with reasoning},
  author = {E Zelikman, Y Wu, J Mu…},
  year = {2022},
  journal = {Advances in Neural …, 2022},
  publisher = {proceedings.neurips.cc},
  abstract = {… for LLMs across diverse tasks including mathematical reasoning, commonsense reasoning, 
… works has emerged exploring the capacity for large language models to perform in-context …},
  url = {https://proceedings.neurips.cc/paper_files/paper/2022/hash/639a9a172c044fbb64175b5fad42e9a5-Abstract-Conference.html},
  note = {Retrieved from Google Scholar}
}

@article{Mrkl2022,
  title = {MRKL Systems: A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning},
  author = {E Karpas, O Abend, Y Belinkov, B Lenz…},
  year = {2022},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {arxiv.org},
  abstract = {… And mathematical reasoning is just the tip of an iceberg. … Despite all these shortcomings, 
large language models are an essential backbone of any future AI system. So the question is …},
  url = {https://arxiv.org/abs/2205.00445},
  note = {Retrieved from Google Scholar}
}

@article{Language2022,
  title = {Language models are greedy reasoners: A systematic formal analysis of chain-of-thought},
  author = {A Saparov, H He},
  year = {2022},
  journal = {arXiv preprint arXiv:2210.01240, 2022},
  publisher = {arxiv.org},
  abstract = {… Large language models (LLMs) have shown remarkable … downstream tasks such as 
mathematical reasoning. However, … of that of general mathematical reasoning. Mathematical …},
  url = {https://arxiv.org/abs/2210.01240},
  note = {Retrieved from Google Scholar}
}

@article{Evaluating2022,
  title = {Evaluating transformer language models on arithmetic operations using number decomposition},
  author = {M Muffo, A Cocco, E Bertino},
  year = {2022},
  journal = {Proceedings of the Thirteenth …, 2022},
  publisher = {aclanthology.org},
  abstract = {… Abstract In recent years, Large Language Models such as GPT-3 showed remarkable … 
the tasks analysed, suggesting that there is large room for improving mathematical reasoning …},
  url = {https://aclanthology.org/2022.lrec-1.30/},
  note = {Retrieved from Google Scholar}
}

@article{What2022,
  title = {What do large language models learn beyond language?},
  author = {A Madasu, S Srivastava},
  year = {2022},
  journal = {arXiv preprint arXiv:2210.12302, 2022},
  publisher = {arxiv.org},
  abstract = {… Large language models (LMs) have rapidly become a mainstay in Natural Language Processing. … 
Further, previous methods explore mathematical reasoning tasks posed as language …},
  url = {https://arxiv.org/abs/2210.12302},
  note = {Retrieved from Google Scholar}
}

@article{Language2022b,
  title = {Language models show human-like content effects on reasoning},
  author = {I Dasgupta, AK Lampinen, SCY Chan…},
  year = {2022},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {stanford.edu},
  abstract = {… More recently, large language models have been similarly shown to accurately predict 
neural representations in the human language system — large language models “predict nearly …},
  url = {http://web.stanford.edu/~jlmcc/papers/DasguptaLampinenEtAl22LMsShowHumanLikeContentEffectsInReasoning.pdf},
  note = {Retrieved from Google Scholar}
}

@article{Structured2022,
  title = {Structured, flexible, and robust: benchmarking and improving large language models towards more human-like behavior in out-of-distribution reasoning tasks},
  author = {KM Collins, C Wong, J Feng, M Wei…},
  year = {2022},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {arxiv.org},
  abstract = {… Our results in Part I suggest that even very large language models may not capture the 
characteristic flexibility of human reasoning: they struggle to produce language reflecting novel …},
  url = {https://arxiv.org/abs/2205.05718},
  note = {Retrieved from Google Scholar}
}

@article{Dynamic2022,
  title = {Dynamic prompt learning via policy gradient for semi-structured mathematical reasoning},
  author = {P Lu, L Qiu, KW Chang, YN Wu, SC Zhu…},
  year = {2022},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {arxiv.org},
  abstract = {… system needs to perform mathematical reasoning over multi-… that requires mathematical 
reasoning over heterogeneous … mathematical reasoning and tabular context are necessary. …},
  url = {https://arxiv.org/abs/2209.14610},
  note = {Retrieved from Google Scholar}
}

@article{Teaching2022,
  title = {Teaching algorithmic reasoning via in-context learning},
  author = {H Zhou, A Nova, H Larochelle, A Courville…},
  year = {2022},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {arxiv.org},
  abstract = {… Large language models (LLMs) have shown increasing in-context learning capabilities … In 
this approach, we utilize one model for performing the informal mathematical reasoning steps …},
  url = {https://arxiv.org/abs/2211.09066},
  note = {Retrieved from Google Scholar}
}

@article{Overcoming2022,
  title = {Overcoming barriers to skill injection in language modeling: Case study in arithmetic},
  author = {M Sharma, N Muralidhar, N Ramakrishnan},
  year = {2022},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {arxiv.org},
  abstract = {… that also happens to be proficient in mathematical reasoning is not as straight-forward as … 
inherent numerical skills induced in large language models through unsupervised training [23, …},
  url = {https://arxiv.org/abs/2211.02098},
  note = {Retrieved from Google Scholar}
}

@article{Language2022c,
  title = {Language models of protein sequences at the scale of evolution enable accurate structure prediction},
  author = {Z Lin, H Akin, R Rao, B Hie, Z Zhu, W Lu…},
  year = {2022},
  journal = {BioRxiv, 2022},
  publisher = {biorxiv.org},
  abstract = {… Large language models have recently been shown to develop emergent capabilities with … 
-shot language translation, commonsense reasoning, and mathematical reasoning (11–14). To …},
  url = {https://www.biorxiv.org/content/10.1101/2022.07.20.500902v1.full.pdf?utm_campaign=M2D2%20Community%20Round-Up&utm_medium=email&utm_source=Revue%20newsletter},
  note = {Retrieved from Google Scholar}
}

@article{Formal2022,
  title = {Formal premise selection with language models},
  author = {Y Wu},
  year = {2022},
  journal = {Conference on Artificial Intelligence and Theorem …, 2022},
  publisher = {aitp},
  abstract = {… Program synthesis with large language models, 2021. … Evaluating large language models 
trained on code, 2021. … Isarstep: a benchmark for high-level mathematical reasoning. In …},
  url = {http://aitp-conference.org/2022/abstract/AITP_2022_paper_32.pdf},
  note = {Retrieved from Google Scholar}
}

@article{Causalguard2022,
  title = {CausalGuard: A Smart System for Detecting and Preventing False Information in Large Language Models},
  author = {P Patel},
  year = {2022},
  journal = {2022},
  publisher = {researchgate.net},
  abstract = {… While large language models have transformed … Mathematical Reasoning: While showing 
improvement over baselines on GSM8K (83.5%) and MATH (79.2%), mathematical reasoning …},
  url = {https://www.researchgate.net/profile/Piyushkumar-Patel-4/publication/397207990_CausalGuard_A_Smart_System_for_Detecting_and_Preventing_False_Information_in_Large_Language_Models/links/6908e0eea404d65709a2146d/CausalGuard-A-Smart-System-for-Detecting-and-Preventing-False-Information-in-Large-Language-Models.pdf},
  note = {Retrieved from Google Scholar}
}

@article{Thor2022,
  title = {Thor: Wielding hammers to integrate language models and automated theorem provers},
  author = {AQ Jiang, W Li, S Tworkowski…},
  year = {2022},
  journal = {Advances in …, 2022},
  publisher = {proceedings.neurips.cc},
  abstract = {In theorem proving, the task of selecting useful premises from a large library to unlock the 
proof of a given conjecture is crucially important. This presents a challenge for all theorem …},
  url = {https://proceedings.neurips.cc/paper_files/paper/2022/hash/377c25312668e48f2e531e2f2c422483-Abstract-Conference.html},
  note = {Retrieved from Google Scholar}
}

@article{LearnUnknown,
  title = {Learn to Select Good Examples with Reinforcement Learning for Semi-structured Mathematical Reasoning},
  author = {P Lu, L Qiu, KW Chang, YN Wu, SC Zhu, T Rajpurohit…},
  journal = {mathai2022.github.io},
  abstract = {… remarkable progress on mathematical reasoning tasks written … problems that require 
mathematical reasoning on both textual … mathematical reasoning and tabular context are …},
  url = {https://mathai2022.github.io/papers/12.pdf},
  note = {Retrieved from Google Scholar}
}

@article{Review2022,
  title = {A review on language models as knowledge bases},
  author = {B AlKhamissi, M Li, A Celikyilmaz, M Diab…},
  year = {2022},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {arxiv.org},
  abstract = {Recently, there has been a surge of interest in the NLP community on the use of pretrained 
Language Models (LMs) as Knowledge Bases (KBs). Researchers have shown that LMs …},
  url = {https://arxiv.org/abs/2204.06031},
  note = {Retrieved from Google Scholar}
}

@article{Learning2022,
  title = {Learning to reason with relational abstractions},
  author = {AJ Nam, M Ren, C Finn, JL McClelland},
  year = {2022},
  journal = {arXiv preprint arXiv:2210.02615, 2022},
  publisher = {arxiv.org},
  abstract = {… Large language models have recently shown promising progress in mathematical reasoning 
when … how language models perform on tasks requiring multi-step mathematical reasoning. …},
  url = {https://arxiv.org/abs/2210.02615},
  note = {Retrieved from Google Scholar}
}

@article{Learn2022,
  title = {Learn to explain: Multimodal reasoning via thought chains for science question answering},
  author = {P Lu, S Mishra, T Xia, L Qiu…},
  year = {2022},
  journal = {Advances in …, 2022},
  publisher = {proceedings.neurips.cc},
  abstract = {… Instead, we find that CoT can help large language models not only in the few-shot learning 
setting but also in the fine-tuning setting. When combined with CoT to generate the lecture …},
  url = {https://proceedings.neurips.cc/paper_files/paper/2022/hash/11332b6b6cf4485b84afadb1352d3a9a-Abstract-Conference.html},
  note = {Retrieved from Google Scholar}
}

@article{Proofnet2022,
  title = {ProofNet: A benchmark for autoformalizing and formally proving undergraduate-level mathematics problems},
  author = {Z Azerbayev, B Piotrowski…},
  year = {2022},
  journal = {Second MATH},
  publisher = {AI …, 2022},
  abstract = {… has been to treat mathematical reasoning in natural language as … A key advantage of 
mathematical reasoning in natural … We have shown that pre-trained large language models …},
  url = {https://mathai2022.github.io/papers/20.pdf},
  note = {Retrieved from Google Scholar}
}

@article{Impact2022,
  title = {Impact of pretraining term frequencies on few-shot reasoning},
  author = {Y Razeghi, RL Logan IV, M Gardner…},
  year = {2022},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {arxiv.org},
  abstract = {… the reasoning evaluation schemes for the large language models. Further characterizing the 
… should not treat the pretraining data of the large language models as unknown black boxes. …},
  url = {https://arxiv.org/abs/2202.07206},
  note = {Retrieved from Google Scholar}
}

@article{Cognitive2022,
  title = {Cognitive Architectures for Explainable AI: Integrating Chain-of-Thought Reasoning in LLMs},
  author = {H Ahmad, M Daviglus},
  year = {2022},
  journal = {2022},
  publisher = {researchgate.net},
  abstract = {… As large language models (LLMs) become increasingly … Thought (CoT) reasoning in large 
language models (LLMs) has … logical inference, mathematical reasoning, and structured …},
  url = {https://www.researchgate.net/profile/Mendus-Daviglus/publication/388835264_Cognitive_Architectures_for_Explainable_AI_Integrating_Chain-of-_Thought_Reasoning_in_LLMs/links/67a908be4c479b26c9db9a3e/Cognitive-Architectures-for-Explainable-AI-Integrating-Chain-of-Thought-Reasoning-in-LLMs.pdf},
  note = {Retrieved from Google Scholar}
}

@article{Outof2022,
  title = {Outof-distribution generalization in algorithmic reasoning through curriculum learning},
  author = {AJ Nam, M Abdool, T Maxfield…},
  year = {2022},
  journal = {CoRR abs …, 2022},
  publisher = {mathai2022.github.io},
  abstract = {… Large transformer-based ‘foundation’ models [1] have attracted recent attention by showing 
some success in mathematical reasoning tasks, demonstrating a degree of systematicity and …},
  url = {https://mathai2022.github.io/papers/22.pdf},
  note = {Retrieved from Google Scholar}
}

@article{Draft2022,
  title = {Draft, sketch, and prove: Guiding formal theorem provers with informal proofs},
  author = {AQ Jiang, S Welleck, JP Zhou, W Li, J Liu…},
  year = {2022},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {arxiv.org},
  abstract = {… We hypothesize that this technique is beneficial for large language models to synthesize 
formal sketches. To validate this hypothesis, we perform an ablation study by removing the in-…},
  url = {https://arxiv.org/abs/2210.12283},
  note = {Retrieved from Google Scholar}
}

@article{Question2022,
  title = {Is a question decomposition unit all we need?},
  author = {P Patel, S Mishra, M Parmar, C Baral},
  year = {2022},
  journal = {arXiv preprint arXiv:2205.12538, 2022},
  publisher = {arxiv.org},
  abstract = {… Large Language Models (LMs) have achieved state-of-the-art performance on many Natu… 
Numglue: A suite of fundamental yet challenging mathematical reasoning tasks. In …},
  url = {https://arxiv.org/abs/2205.12538},
  note = {Retrieved from Google Scholar}
}

@article{Mind2022,
  title = {Mind's eye: Grounded language model reasoning through simulation},
  author = {R Liu, J Wei, SS Gu, TY Wu, S Vosoughi, C Cui…},
  year = {2022},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {arxiv.org},
  abstract = {… This setting is also different from those in mathematical reasoning tasks (eg, GSM8k (Cobbe … 
Chain of thought prompting elicits reasoning in large language models. Conference on …},
  url = {https://arxiv.org/abs/2210.05359},
  note = {Retrieved from Google Scholar}
}

@article{Branch2022,
  title = {Branch-train-merge: Embarrassingly parallel training of expert language models},
  author = {M Li, S Gururangan, T Dettmers, M Lewis…},
  year = {2022},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {arxiv.org},
  abstract = {… We present Branch-Train-Merge (BTM), a communication-efficient algorithm for 
embarrassingly parallel training of large language models (LLMs). We show it is possible to …},
  url = {https://arxiv.org/abs/2208.03306},
  note = {Retrieved from Google Scholar}
}

@article{Composing2022,
  title = {Composing ensembles of pre-trained models via iterative consensus},
  author = {S Li, Y Du, JB Tenenbaum, A Torralba…},
  year = {2022},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {arxiv.org},
  abstract = {… method can be used as a general purpose framework for a wide range of zero-shot 
multimodal tasks, such as image generation, video question answering, mathematical reasoning, …},
  url = {https://arxiv.org/abs/2210.11522},
  note = {Retrieved from Google Scholar}
}

@article{Language2022d,
  title = {Language models are general-purpose interfaces},
  author = {Y Hao, H Song, L Dong, S Huang, Z Chi…},
  year = {2022},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {arxiv.org},
  abstract = {Foundation models have received much attention due to their effectiveness across a broad 
range of downstream applications. Though there is a big convergence in terms of architecture…},
  url = {https://arxiv.org/abs/2206.06336},
  note = {Retrieved from Google Scholar}
}

@article{Very2022,
  title = {Very large language model as a unified methodology of text mining},
  author = {M Jiang},
  year = {2022},
  journal = {arXiv preprint arXiv:2212.09271, 2022},
  publisher = {arxiv.org},
  abstract = {… on story writing, question answering, or mathematical reasoning just by conditioning on input-… 
Generate rather than retrieve: Large language models are strong context generators. arXiv …},
  url = {https://arxiv.org/abs/2212.09271},
  note = {Retrieved from Google Scholar}
}

@article{Language2022e,
  title = {Language models can teach themselves to program better},
  author = {P Haluptzok, M Bowers, AT Kalai},
  year = {2022},
  journal = {arXiv preprint arXiv:2207.14502, 2022},
  publisher = {arxiv.org},
  abstract = {Recent Language Models (LMs) achieve breakthrough performance in code generation 
when trained on human-authored problems, even solving some competitive-programming …},
  url = {https://arxiv.org/abs/2207.14502},
  note = {Retrieved from Google Scholar}
}

@article{Proceedings2022,
  title = {Proceedings of the 2nd Workshop on Natural Language Generation, Evaluation, and Metrics (GEM)},
  author = {A Bosselut, K Chandu, K Dhole, V Gangal…},
  year = {2022},
  journal = {Proceedings of the …, 2022},
  publisher = {aclanthology.org},
  abstract = {… Abstract: While research on large language models (LLMs) … door to tackling challenging 
mathematical reasoning tasks. Join me … focus on mathematical reasoning. He received his Ph.D. …},
  url = {https://aclanthology.org/2022.gem-1.0.pdf},
  note = {Retrieved from Google Scholar}
}

@article{Text2022,
  title = {Text and patterns: For effective chain of thought, it takes two to tango},
  author = {A Madaan, A Yazdanbakhsh},
  year = {2022},
  journal = {arXiv preprint arXiv:2209.07686, 2022},
  publisher = {arxiv.org},
  abstract = {… an unprecedented scaling of large language models. These … pushes the performance of 
large language models in a few-… tasks and across three large language models—PaLM, GPT-…},
  url = {https://arxiv.org/abs/2209.07686},
  note = {Retrieved from Google Scholar}
}

@article{Generating2022,
  title = {Generating sequences by learning to self-correct},
  author = {S Welleck, X Lu, P West, F Brahman, T Shen…},
  year = {2022},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {arxiv.org},
  abstract = {… the promise of using (self-)correctors for controlling the outputs of large language models. … 
Chain of thought prompting elicits reasoning in large language models. ArXiv, abs/2201.11903…},
  url = {https://arxiv.org/abs/2211.00053},
  note = {Retrieved from Google Scholar}
}

@article{Exploring2022,
  title = {Exploring Communicative Strategies for Dual LLM Agents in Mathematical Problem Solving},
  author = {L Zhang, J Lin, X Zhai, D Zapata},
  year = {2022},
  journal = {Rivera, C Forsyth…},
  publisher = {2022},
  abstract = {… The advancement of multi-agent workflows leveraging Large Language Models (LLMs) 
for tackling complex tasks, such as mathematical problem-solving, has garnered significant …},
  url = {https://www.researchgate.net/profile/Liang-Zhang-10/publication/390466024_Exploring_Communicative_Strategies_for_Dual_LLM_Agents_in_Mathematical_Problem_Solving/links/67eeea71e8041142a161472a/Exploring-Communicative-Strategies-for-Dual-LLM-Agents-in-Mathematical-Problem-Solving.pdf},
  note = {Retrieved from Google Scholar}
}

@article{Memorizing2022,
  title = {Memorizing transformers},
  author = {Y Wu, MN Rabe, DL Hutchins, C Szegedy},
  year = {2022},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {arxiv.org},
  abstract = {… The simplicity of the changes to the Transformer architecture allows us to easily integrate 
this approach into existing code bases, including extremely large language models. We further …},
  url = {https://arxiv.org/abs/2203.08913},
  note = {Retrieved from Google Scholar}
}

@article{Neural2022,
  title = {A neural network solves, explains, and generates university math problems by program synthesis and few-shot learning at human level},
  author = {I Drori, S Zhang, R Shuttleworth, L Tang, A Lu…},
  year = {2022},
  journal = {Proceedings of the …, 2022},
  publisher = {pnas.org},
  abstract = {… and Probability, Intermediate Algebra, Number Theory, and Precalculus), the latest 
benchmark of advanced mathematics problems designed to assess mathematical reasoning. We …},
  url = {https://www.pnas.org/doi/abs/10.1073/pnas.2123433119},
  note = {Retrieved from Google Scholar}
}

@article{Numerical2022,
  title = {Numerical Correlation in Text},
  author = {D Spokoyny, CS Wu, C Xiong},
  year = {2022},
  journal = {Proceedings of the 1st Workshop …, 2022},
  publisher = {aclanthology.org},
  abstract = {… Evaluation of quantitative reasoning of large language models is an important step towards 
understanding their current capabilities and limitations. We propose a new task, Numerical …},
  url = {https://aclanthology.org/2022.mathnlp-1.5/},
  note = {Retrieved from Google Scholar}
}

@article{Achieving2022,
  title = {Achieving and Understanding Out-of-Distribution Generalization in Systematic Reasoning in Small-Scale Transformers},
  author = {AJ Nam, M Abdool, T Maxfield…},
  year = {2022},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {arxiv.org},
  abstract = {… by showing some success in mathematical reasoning tasks, demonstrating a degree of … 
of large transformer-based models, especially in large language models such as GPT-3 [3] …},
  url = {https://arxiv.org/abs/2210.03275},
  note = {Retrieved from Google Scholar}
}

@article{Formal2022b,
  title = {Formal specifications from natural language},
  author = {C Hahn, F Schmitt, JJ Tillman, N Metzger…},
  year = {2022},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {arxiv.org},
  abstract = {We study the generalization abilities of language models when translating natural language 
into formal specifications with complex semantics. In particular, we fine-tune language …},
  url = {https://arxiv.org/abs/2206.01962},
  note = {Retrieved from Google Scholar}
}

@article{Correctness2022,
  title = {Correctness Comparison of ChatGPT-4, Bard, Claude-2, and Copilot for Spatial Tasks. 2},
  author = {HH Hochmaira, L Juhászb, T Kempa},
  year = {2022},
  journal = {2022},
  publisher = {researchgate.net},
  abstract = {… Generative AI including large language models (LLMs) have recently gained significant … 
, while Claude-2 demonstrates strengths in mathematical reasoning (Barilla, 2023). Bard AI is …},
  url = {https://www.researchgate.net/profile/Levente-Juhasz/publication/377178667_Correctness_Comparison_of_ChatGPT-4_Gemini_Claude-3_and_Copilot_for_Spatial_Tasks/links/659821c80bb2c7472b361688/Correctness-Comparison-of-ChatGPT-4-Gemini-Claude-3-and-Copilot-for-Spatial-Tasks.pdf},
  note = {Retrieved from Google Scholar}
}

@article{MileUnknown,
  title = {MILE: Memory-Interactive Learning Engine for Solving Mathematical Problems},
  author = {Y Wu, H Nakayama},
  journal = {openreview.net},
  abstract = {… Mathematical reasoning is a field quite suitable for this study because of its high-level … 
Prompt programming for large language models: Beyond the few-shot paradigm. In Extended …},
  url = {https://openreview.net/forum?id=nQtcJ24_45K},
  note = {Retrieved from Google Scholar}
}

@article{Star2022b,
  title = {Star: Self-taught reasoner},
  author = {E Zelikman, Y Wu…},
  year = {2022},
  journal = {Proceedings of the …, 2022},
  publisher = {raw.githubusercontent.com},
  abstract = {… ” for intermediate steps, large language models (LLMs) can … range of tasks including 
mathematical reasoning, commonsense … In addition, as text generation by large language models …},
  url = {https://raw.githubusercontent.com/labmlai/annotated_deep_learning_paper_implementations/master/papers/2203.14465.pdf},
  note = {Retrieved from Google Scholar}
}

@article{Multi2022,
  title = {Multi-lingual evaluation of code generation models},
  author = {B Athiwaratkun, SK Gouda, Z Wang, X Li, Y Tian…},
  year = {2022},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {arxiv.org},
  abstract = {… models on complex context, which requires mathematical reasoning. Similar to Section 4.4 
and … More recently, various work have been proposed to use large language models for code …},
  url = {https://arxiv.org/abs/2210.14868},
  note = {Retrieved from Google Scholar}
}

@article{Parallel2022,
  title = {A parallel corpus of natural language and isabelle artefacts},
  author = {A Bordg, YA Stathopoulos…},
  year = {2022},
  journal = {7th Conference on …, 2022},
  publisher = {aitp},
  abstract = {… Evaluating large language models trained on code. 2021. … Mathematical reasoning via 
self-supervised skip-tree training. In International Conference on Learning Representations, 2021…},
  url = {http://aitp-conference.org/2022/abstract/AITP_2022_paper_8.pdf},
  note = {Retrieved from Google Scholar}
}

@article{Impact2022b,
  title = {The impact of symbolic representations on in-context learning for few-shot reasoning},
  author = {H Zhang, YF Zhang, LE Li, E Xing},
  year = {2022},
  journal = {NeurIPS 2022 Workshop on …, 2022},
  publisher = {openreview.net},
  abstract = {… Chain of thought prompting elicits reasoning in large language models. arXiv preprint 
arXiv:… Least-to-most prompting enables complex reasoning in large language models. arXiv …},
  url = {https://openreview.net/forum?id=qLgQpeQX3x1},
  note = {Retrieved from Google Scholar}
}

@article{Teaching2022b,
  title = {Teaching broad reasoning skills for multi-step QA by generating hard contexts},
  author = {H Trivedi, N Balasubramanian, T Khot…},
  year = {2022},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {arxiv.org},
  abstract = {… Our experiments demonstrate that pretraining3 large language models (LMs) on TEABREAC 
before fine-tuning on target multi-step QA datasets results in significant improvements on …},
  url = {https://arxiv.org/abs/2205.12496},
  note = {Retrieved from Google Scholar}
}

@article{Logical2022,
  title = {Logical tasks for measuring extrapolation and rule comprehension},
  author = {I Fujisawa, R Kanai},
  year = {2022},
  journal = {arXiv preprint arXiv:2211.07727, 2022},
  publisher = {arxiv.org},
  abstract = {… There are no reliable large language models to do this with symbolic operations. GPT-3 
fails to solve elementary arithmetic equations. It works well on twodigit addition, but accuracy …},
  url = {https://arxiv.org/abs/2211.07727},
  note = {Retrieved from Google Scholar}
}

@article{Survey2022,
  title = {A survey in mathematical language processing},
  author = {J Meadows, A Freitas},
  year = {2022},
  journal = {arXiv preprint arXiv:2205.15231, 2022},
  publisher = {arxiv.org},
  abstract = {… Delivering mathematical reasoning over discourse requires close integration between 
step-wise inference control over localised explicit representations (symbolic perspective), and dis…},
  url = {https://arxiv.org/abs/2205.15231},
  note = {Retrieved from Google Scholar}
}

@article{Unveiling2022,
  title = {Unveiling transformers with lego: a synthetic reasoning task},
  author = {Y Zhang, A Backurs, S Bubeck, R Eldan…},
  year = {2022},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {arxiv.org},
  abstract = {We propose a synthetic reasoning task, LEGO (Learning Equality and Group Operations), 
that encapsulates the problem of following a chain of reasoning, and we study how the …},
  url = {https://arxiv.org/abs/2206.04301},
  note = {Retrieved from Google Scholar}
}

@article{Teaching2022c,
  title = {Teaching Broad Reasoning Skills via Decomposition-Guided Contexts},
  author = {H Trivedi, N Balasubramanian, T Khot…},
  year = {2022},
  journal = {Proceedings of the 2022 …, 2022},
  publisher = {par.nsf.gov},
  abstract = {… Our experiments demonstrate that pretraining3 large language models (LMs) on TEABREAC 
before fine-tuning on target multi-step QA datasets results in significant improvements on …},
  url = {https://par.nsf.gov/biblio/10432871},
  note = {Retrieved from Google Scholar}
}

@article{Program2022b,
  title = {Program synthesis for integer sequence generation},
  author = {N Butt, A Wiggers, T Cohen, M Welling},
  year = {2022},
  journal = {2022},
  publisher = {mathai2022.github.io},
  abstract = {Recent advances in program synthesis have shown success with methods that employ 
supervised learning on synthetic data generated from domain specific languages (DSLs). In this …},
  url = {https://mathai2022.github.io/papers/24.pdf},
  note = {Retrieved from Google Scholar}
}

@article{Automatically2022,
  title = {Automatically answering and generating machine learning final exams},
  author = {S Zhang, RS Shuttleworth, Z Chin, P Lantigua…},
  year = {2022},
  journal = {2022},
  publisher = {openreview.net},
  abstract = {… We use the latest OpenAI GPT-3 and Codex models and do not re-train these very large 
language models. We fix all the hyperparameters of the models so that the answers are …},
  url = {https://openreview.net/forum?id=MT1Pcdo8sGG},
  note = {Retrieved from Google Scholar}
}

@article{Algorithmic2022,
  title = {Algorithmic Dimensions, the Point-To-Set Principles, and the Complexity of Oracles},
  author = {E Mayordomo Cámara},
  year = {2022},
  journal = {2022},
  publisher = {zaguan.unizar.es},
  abstract = {… With the advent of the “golden age of Natural Language Processing” [1] (NLP), a contagious 
enthusiasm on the capabilities of large language models (LLMs) started spreading from …},
  url = {https://zaguan.unizar.es/record/121866},
  note = {Retrieved from Google Scholar}
}

@article{Jrird2022,
  title = {JRIRD at the NTCIR-16 FinNum-3 Task: Investigating the Effect of Numerical Representations in Manager's Claim Detection},
  author = {S Onuma, K Kadowaki},
  year = {2022},
  journal = {… of the 16th NTCIR Conference on …, 2022},
  publisher = {research.nii.ac.jp},
  abstract = {… However, the performance of large language models worsened in some formats. … 
Mathematical Reasoning in General Artificial Intelligence Workshop at ICLR 2021. …},
  url = {https://research.nii.ac.jp/ntcir/workshop/OnlineProceedings16/pdf/ntcir/05-NTCIR16-FINNUM-OnumaS.pdf},
  note = {Retrieved from Google Scholar}
}

@article{Towards2022,
  title = {Towards data-and knowledge-driven artificial intelligence: A survey on neuro-symbolic computing},
  author = {W Wang, Y Yang, F Wu},
  year = {2022},
  journal = {arXiv preprint arXiv:2210.15889, 2022},
  publisher = {arxiv.org},
  abstract = {… diagnosis, autonomous driving, and mathematical reasoning, and lead to the increasing … 
NLP systems, including large language models like GPT3 [61], fall under this category (see …},
  url = {https://arxiv.org/abs/2210.15889},
  note = {Retrieved from Google Scholar}
}

@article{Sqa3d2022,
  title = {Sqa3d: Situated question answering in 3d scenes},
  author = {X Ma, S Yong, Z Zheng, Q Li, Y Liang, SC Zhu…},
  year = {2022},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {arxiv.org},
  abstract = {… Finally, we explore whether powerful Large Language Models (LLMs) like GPT-3 (Brown et 
al… Chain of thought prompting elicits reasoning in large language models. arXiv preprint arXiv:…},
  url = {https://arxiv.org/abs/2210.07474},
  note = {Retrieved from Google Scholar}
}

@article{Inside2022,
  title = {Inside the Mind of an AI: Materiality and the Crisis of Representation},
  author = {NK Hayles},
  year = {2022},
  journal = {New Literary History, 2022},
  publisher = {muse.jhu.edu},
  abstract = {… —also have cognitive capabilities, as do large language models [End Page 652] such as … 
be true, a tactic sometimes used in mathematical reasoning). However, it immediately qualifies …},
  url = {https://muse.jhu.edu/pub/1/article/898324/summary},
  note = {Retrieved from Google Scholar}
}

@article{Mathematical2022,
  title = {Mathematical proof between generations},
  author = {J Bayer, C Benzmüller, K Buzzard, M David, L Lamport…},
  year = {2022},
  journal = {2022},
  publisher = {ams.org},
  abstract = {… Another possibility is training large language models such as ChatGPT to write Lean code. 
… The idea of applying technology to mathematical reasoning began to be realized in the 1960s…},
  url = {https://www.ams.org/journals/notices/202401/rnoti-p79.pdf},
  note = {Retrieved from Google Scholar}
}

@article{Mathematical2022b,
  title = {Mathematical intelligence: what we have that machines don't},
  author = {J Mubeen},
  year = {2022},
  journal = {2022},
  publisher = {books.google.com},
  abstract = {… the confabulatory behaviours of large language models long before … Large language models 
set machines on a 'mindless' path … Large language models already depend a great deal on …},
  url = {https://books.google.com/books?hl=en&lr=&id=3-JBEAAAQBAJ&oi=fnd&pg=PT4&dq=%22large+language+models%22+%22mathematical+reasoning%22&ots=HMTZF9rDeK&sig=VogUX0Ua4JpCJFOvcf5mdc3oZto},
  note = {Retrieved from Google Scholar}
}

@article{Some2022,
  title = {Some representation learning tasks and the inspection of their models},
  author = {L Pfahler},
  year = {2022},
  journal = {2022},
  publisher = {eldorado.tu},
  abstract = {… Bender et al. demonstrate the dangers of training large language models on web crawls with 
little quality control [14], including how small diversity in the data can lead to discrimination, …},
  url = {https://eldorado.tu-dortmund.de/bitstream/2003/41168/1/dissertation.pdf},
  note = {Retrieved from Google Scholar}
}

@article{Neurosymbolic2022,
  title = {Neurosymbolic Machine Learning for Reasoning},
  author = {K Yang},
  year = {2022},
  journal = {2022},
  publisher = {search.proquest.com},
  abstract = {… Proof assistants offer a formalism that resembles human mathematical reasoning, representing 
theorems in higher-order logic and proofs as high-level tactics. However, human experts …},
  url = {https://search.proquest.com/openview/2ab78d5c4887ddfe4b34a1cde865a303/1?pq-origsite=gscholar&cbl=18750&diss=y},
  note = {Retrieved from Google Scholar}
}

@article{Natural2022,
  title = {Natural language deduction through search over statement compositions},
  author = {K Bostrom, Z Sprague, S Chaudhuri…},
  year = {2022},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {arxiv.org},
  abstract = {In settings from fact-checking to question answering, we frequently want to know whether a 
collection of evidence (premises) entails a hypothesis. Existing methods primarily focus on …},
  url = {https://arxiv.org/abs/2201.06028},
  note = {Retrieved from Google Scholar}
}

@article{Neuro2022,
  title = {Is neuro-symbolic ai meeting its promise in natural language processing? a structured},
  author = {K Hamilton, A Nayak, B Božic, L Longo},
  year = {2022},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {academia.edu},
  abstract = {… , the success of the Transformer and Large Language Models (LLMs) has also served to … 
types of logic, human reasoning, and mathematical reasoning, as well as counter-productive …},
  url = {https://www.academia.edu/download/95152225/2202.12205.pdf},
  note = {Retrieved from Google Scholar}
}

@article{Expert2022,
  title = {A non-expert's introduction to data ethics for mathematicians},
  author = {MA Porter},
  year = {2022},
  journal = {2022},
  publisher = {books.google.com},
  abstract = {… There are significant risks and potential nefarious uses of tools like generative AI and large 
language models (LLMs) [ BGMMS21 , EMFG+22 , Fer24 ]. Modern data analysis also has …},
  url = {https://books.google.com/books?hl=en&lr=&id=fNhcEQAAQBAJ&oi=fnd&pg=PA65&dq=%22large+language+models%22+%22mathematical+reasoning%22&ots=ttLO9dgRNm&sig=Z5Kqd1hwOifqHEBoH6BIxwx00Us},
  note = {Retrieved from Google Scholar}
}

@article{TowardsUnknown,
  title = {Towards neuro-symbolic conjecturing},
  author = {SH Einarsdóttir, M Johansson, N Smallbone},
  journal = {aitp},
  publisher = {conference.org},
  abstract = {… There have been recent attempts to use large language models for conjecturing tasks [8… 
Mathematical reasoning via self-supervised skiptree training. In Proceedings of ICLR, 2021. …},
  url = {http://aitp-conference.org/2022/abstract/AITP_2022_paper_13.pdf},
  note = {Retrieved from Google Scholar}
}

@article{Open2022,
  title = {Open-Ended Knowledge Tracing},
  author = {N Liu, Z Wang, RG Baraniuk…},
  year = {2022},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {people.umass.edu},
  abstract = {ABSTRACT Knowledge tracing refers to the problem of estimating each student’s knowledge 
component/skill mastery level from their past responses to questions in educational …},
  url = {https://people.umass.edu/~andrewlan/papers/preprint-OKT.pdf},
  note = {Retrieved from Google Scholar}
}

@article{Exploring2022b,
  title = {Exploring the landscape of distributional robustness for question answering models},
  author = {A Awadalla, M Wortsman, G Ilharco, S Min…},
  year = {2022},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {arxiv.org},
  abstract = {… This is particularly useful for very large language models, where fine-tuning is expensive. 
In-context learning refers to the process of conditioning a language model on one or more …},
  url = {https://arxiv.org/abs/2210.12517},
  note = {Retrieved from Google Scholar}
}

@article{Machine2022,
  title = {Machine learning and logic: a new frontier in artificial intelligence},
  author = {V Ganesh, SA Seshia, S Jha},
  year = {2022},
  journal = {Formal Methods in System Design, 2022},
  publisher = {Springer},
  abstract = {Abstract Machine learning and logical reasoning have been the two foundational pillars of 
Artificial Intelligence (AI) since its inception, and yet, until recently the interactions between …},
  url = {https://link.springer.com/article/10.1007/s10703-023-00430-1},
  note = {Retrieved from Google Scholar}
}

@article{Transformers2022,
  title = {Transformers learn shortcuts to automata},
  author = {B Liu, JT Ash, S Goel, A Krishnamurthy…},
  year = {2022},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {arxiv.org},
  abstract = {Algorithmic reasoning requires capabilities which are most naturally understood through 
recurrent models of computation, like the Turing machine. However, Transformer models, while …},
  url = {https://arxiv.org/abs/2210.10749},
  note = {Retrieved from Google Scholar}
}

@article{Learning2022b,
  title = {Learning to Discover Proofs and Theorems Without Supervision},
  author = {J Laurent},
  year = {2022},
  journal = {2022},
  publisher = {cs.cmu.edu},
  abstract = {… However, despite impressive progress involving large language models [11] and self-… 
The main computational obstacle to using large language models with our framework is the …},
  url = {https://www.cs.cmu.edu/~jlaurent/pdf/reports/thesis-proposal.pdf},
  note = {Retrieved from Google Scholar}
}

@article{Insights2022,
  title = {Insights into pre-training via simpler synthetic tasks},
  author = {Y Wu, F Li, PS Liang},
  year = {2022},
  journal = {Advances in Neural Information …, 2022},
  publisher = {proceedings.neurips.cc},
  abstract = {Pre-training produces representations that are effective for a wide range of downstream 
tasks, but it is still unclear what properties of pre-training are necessary for effective gains. …},
  url = {https://proceedings.neurips.cc/paper_files/paper/2022/hash/89379d5fc6eb34ff98488202fb52b9d0-Abstract-Conference.html},
  note = {Retrieved from Google Scholar}
}

@article{Informs2022,
  title = {Law informs code: A legal informatics approach to aligning artificial intelligence with humans},
  author = {JJ Nay},
  year = {2022},
  journal = {Nw. J. Tech. & Intell. Prop., 2022},
  publisher = {HeinOnline},
  abstract = {Artificial Intelligence (AI) capabilities are rapidly advancing. Highly capable Al could cause 
radically different futures depending on how it is developed and deployed. We are unable to …},
  url = {https://heinonline.org/hol-cgi-bin/get_pdf.cgi?handle=hein.journals/nwteintp20&section=14},
  note = {Retrieved from Google Scholar}
}

@article{Gathering2022,
  title = {Gathering strength, gathering storms: The one hundred year study on artificial intelligence (AI100) 2021 study panel report},
  author = {ML Littman, I Ajunwa, G Berger, C Boutilier…},
  year = {2022},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {arxiv.org},
  abstract = {… Spotify’s use of audio analysis of music40 or the application of large language models … 
.org/how-close-are-computers-to-automating-mathematical-reasoning-20200827/ …},
  url = {https://arxiv.org/abs/2210.15767},
  note = {Retrieved from Google Scholar}
}

@article{State2022,
  title = {State-of-the-art generalisation research in NLP: a taxonomy and review},
  author = {D Hupkes, M Giulianelli, V Dankers, M Artetxe…},
  year = {2022},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {arxiv.org},
  abstract = {… of study using very large language models: the computational … the evaluation data of large 
language models makes it hard to … also be conducted with large language models but the lack …},
  url = {https://arxiv.org/abs/2210.03050},
  note = {Retrieved from Google Scholar}
}

@article{Attention2022,
  title = {Attention flows for general transformers},
  author = {N Metzger, C Hahn, J Siber, F Schmitt…},
  year = {2022},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {arxiv.org},
  abstract = {In this paper, we study the computation of how much an input token in a Transformer model 
influences its prediction. We formalize a method to construct a flow network out of the …},
  url = {https://arxiv.org/abs/2205.15389},
  note = {Retrieved from Google Scholar}
}

@article{Vision2022,
  title = {Vision transformers provably learn spatial structure},
  author = {S Jelassi, M Sander, Y Li},
  year = {2022},
  journal = {Advances in Neural Information …, 2022},
  publisher = {proceedings.neurips.cc},
  abstract = {… 67] or in mathematical reasoning [73]. In this paper, we focus on computer vision where 
convolutions are considered to be an adequate and biologically plausible inductive bias since …},
  url = {https://proceedings.neurips.cc/paper_files/paper/2022/hash/f69707de866eb0805683d3521756b73f-Abstract-Conference.html},
  note = {Retrieved from Google Scholar}
}

@article{Neural2022b,
  title = {Neural-symbolic recursive machine for systematic generalization},
  author = {Q Li, Y Zhu, Y Liang, YN Wu, SC Zhu…},
  year = {2022},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {arxiv.org},
  abstract = {… 2020), and large language models have been guided towards compositional semantic parsing 
on CFQ (Drozdov … Compositional semantic parsing with large language models. ICLR. 1…},
  url = {https://arxiv.org/abs/2210.01603},
  note = {Retrieved from Google Scholar}
}

@article{Boxbart2022,
  title = {In-boxbart: Get instructions into biomedical multi-task learning},
  author = {M Parmar, S Mishra, M Purohit, M Luo…},
  year = {2022},
  journal = {Findings of the …, 2022},
  publisher = {aclanthology.org},
  abstract = {Single-task models have proven pivotal in solving specific tasks; however, they have 
limitations in real-world applications where multi-tasking is necessary and domain shifts are …},
  url = {https://aclanthology.org/2022.findings-naacl.10/},
  note = {Retrieved from Google Scholar}
}

@article{Solving2022b,
  title = {Solving probability and statistics problems by probabilistic program synthesis at human level and predicting solvability},
  author = {L Tang, E Ke, N Singh, B Feng, D Austin…},
  year = {2022},
  journal = {… Conference on Artificial …, 2022},
  publisher = {Springer},
  abstract = {We use probabilistic program synthesis to solve questions in MIT and Harvard Probability and 
Statistics courses. Traditional approaches using the latest GPT-3 language model without …},
  url = {https://link.springer.com/chapter/10.1007/978-3-031-11647-6_127},
  note = {Retrieved from Google Scholar}
}

@article{Optimization2022,
  title = {Optimization and High-Dimensional Loss Landscapes in Deep Learning},
  author = {BW Larsen},
  year = {2022},
  journal = {2022},
  publisher = {search.proquest.com},
  abstract = {… (3) In the training of large language models, a common problem is that loss spikes and 
training becomes unstable. A hypothesis for why this phenomenon occurs is that the network is …},
  url = {https://search.proquest.com/openview/3ff627dbe318ef9a8a75d8f91e5773e7/1?pq-origsite=gscholar&cbl=18750&diss=y},
  note = {Retrieved from Google Scholar}
}

@article{Towards2022b,
  title = {Towards learning universal hyperparameter optimizers with transformers},
  author = {Y Chen, X Song, C Lee, Z Wang…},
  year = {2022},
  journal = {Advances in …, 2022},
  publisher = {proceedings.neurips.cc},
  abstract = {Meta-learning hyperparameter optimization (HPO) algorithms from prior experiments is a 
promising approach to improve optimization efficiency over objective functions from a similar …},
  url = {https://proceedings.neurips.cc/paper_files/paper/2022/hash/cf6501108fced72ee5c47e2151c4e153-Abstract-Conference.html},
  note = {Retrieved from Google Scholar}
}

@article{Learning2022c,
  title = {Big Learning},
  author = {Y Cong, M Zhao},
  year = {2022},
  journal = {arXiv preprint arXiv:2207.03899, 2022},
  publisher = {arxiv.org},
  abstract = {Recent advances in big/foundation models reveal a promising path for deep learning, 
where the roadmap steadily moves from big data to big models to (the newly-introduced) big …},
  url = {https://arxiv.org/abs/2207.03899},
  note = {Retrieved from Google Scholar}
}

@article{RevolutionsUnknown,
  title = {Revolutions and Revelations in Computability LNCS 13359},
  author = {U Berger, JNY Franklin, F Manea, A Pauly},
  journal = {Springer},
  abstract = {… With the advent of the “golden age of Natural Language Processing” [1] (NLP), a contagious 
enthusiasm on the capabilities of large language models (LLMs) started spreading from …},
  url = {https://link.springer.com/content/pdf/10.1007/978-3-031-08740-0.pdf},
  note = {Retrieved from Google Scholar}
}

@article{Datasheet2022,
  title = {Datasheet for the pile},
  author = {S Biderman, K Bicheno, L Gao},
  year = {2022},
  journal = {arXiv preprint arXiv:2201.07311, 2022},
  publisher = {arxiv.org},
  abstract = {This datasheet describes the Pile, a 825 GiB dataset of human-authored text compiled by 
EleutherAI for use in large-scale language modeling. The Pile is comprised of 22 different text …},
  url = {https://arxiv.org/abs/2201.07311},
  note = {Retrieved from Google Scholar}
}

@article{Towards2022c,
  title = {Towards Multimodal, Interpretable and Robust Task-Oriented Dialogue Modeling},
  author = {S Yang},
  year = {2022},
  journal = {2022},
  publisher = {minerva},
  abstract = {… which contains about 150 different NLP tasks ranging from text classification, question 
answering, to more difficult tasks such as common sense reasoning and mathematical reasoning. …},
  url = {https://minerva-access.unimelb.edu.au/items/355cb5b3-66da-478d-95a3-7a8d4c28c3a9},
  note = {Retrieved from Google Scholar}
}

@article{Survey2022b,
  title = {A Survey of Parameters Associated with the Quality of Benchmarks in NLP},
  author = {S Mishra, A Arunkumar, C Bryan, C Baral},
  year = {2022},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {arxiv.org},
  abstract = {… Numglue: A suite of fundamental yet challenging mathematical reasoning tasks. In Proceedings 
of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: …},
  url = {https://arxiv.org/abs/2210.07566},
  note = {Retrieved from Google Scholar}
}

@article{Learning2022d,
  title = {Big Learning: A Universal Machine Learning Paradigm?},
  author = {Y Cong, M Zhao},
  year = {2022},
  journal = {2022},
  publisher = {openreview.net},
  abstract = {Recent breakthroughs based on big/foundation models reveal a vague avenue for AI, that is, 
emphbig data, big/foundation models, big learning, $cdots$. Following that avenue, here …},
  url = {https://openreview.net/forum?id=UfFXUfAsnPH},
  note = {Retrieved from Google Scholar}
}

@article{RepairingUnknown,
  title = {Repairing Circuits with Transformers},
  author = {M Cosler},
  journal = {finkbeiner.groups.cispa.de},
  abstract = {In this work, we present an approach for repairing faulty circuits using deep neural networks. 
Given a faulty circuit and a specification in LTL, we demonstrate that our approach repairs …},
  url = {https://finkbeiner.groups.cispa.de/publications/Cosler22.pdf},
  note = {Retrieved from Google Scholar}
}

@article{Revolutions2022,
  title = {Revolutions and Revelations in Computability: 18th Conference on Computability in Europe, CiE 2022, Swansea, UK, July 11–15, 2022, Proceedings},
  author = {U Berger, JNY Franklin, F Manea, A Pauly},
  year = {2022},
  journal = {2022},
  publisher = {books.google.com},
  abstract = {… With the advent of the "golden age of Natural Language Processing" [1] (NLP), a contagious 
enthusiasm on the capabilities of large language models (LLMs) started spreading from …},
  url = {https://books.google.com/books?hl=en&lr=&id=O0p3EAAAQBAJ&oi=fnd&pg=PR5&dq=%22large+language+models%22+%22mathematical+reasoning%22&ots=Wk0RIkrwfs&sig=oTPt5YLYJy2CSLbQjne9crdarX4},
  note = {Retrieved from Google Scholar}
}

@article{Mechanism2022,
  title = {Mechanism of feature learning in deep fully connected networks and kernel machines that recursively learn features},
  author = {A Radhakrishnan, D Beaglehole, P Pandit…},
  year = {2022},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {arxiv.org},
  abstract = {… average gradient outer product as an alternative to backpropagation could reduce the sizeable 
training costs associated with stateof-the-art models, including large language models for …},
  url = {https://arxiv.org/abs/2212.13881},
  note = {Retrieved from Google Scholar}
}

@article{Evaluating2022b,
  title = {Evaluating tools for characterizing anterior urethral stricture disease: a comparison of the LSE system and the urethral stricture score},
  author = {JT Kurtzman, R Kosber, P Kerr…},
  year = {2022},
  journal = {The Journal of …, 2022},
  publisher = {auajournals.org},
  abstract = {… , including deep learning, machine learning and large language models and generative AI. 
… Like the U-Score, point allocation was not based on discrete mathematical reasoning, which …},
  url = {https://www.auajournals.org/doi/abs/10.1097/JU.0000000000002880},
  note = {Retrieved from Google Scholar}
}

@article{SolvingUnknownb,
  title = {Solving quantitative reasoning problems with language models},
  author = {A Lewkowycz, A Andreassen…},
  journal = {Advances in neural …, 2022},
  publisher = {proceedings.neurips.cc},
  abstract = {… In particular, large language models have achieved excellent performance across a 
variety … of the MATH prompt for topics that involve mathematical reasoning, and add step-by-step …},
  url = {https://proceedings.neurips.cc/paper_files/paper/2022/hash/18abbeef8cfe9203fdf9053c9c4fe191-Abstract-Conference.html},
  note = {Retrieved from Google Scholar}
}

@article{AutoformalizationUnknownb,
  title = {Autoformalization with large language models},
  author = {Y Wu, AQ Jiang, W Li, M Rabe…},
  journal = {Advances in neural …, 2022},
  publisher = {proceedings.neurips.cc},
  abstract = {… fields that automate aspects of mathematical reasoning, such as automated … Recent 
advances in large language models [8… with large language models. To our surprise, we find that …},
  url = {https://proceedings.neurips.cc/paper_files/paper/2022/hash/d0c6bc641a56bebee9d985b937307367-Abstract-Conference.html},
  note = {Retrieved from Google Scholar}
}

@article{NaturalproverUnknownb,
  title = {Naturalprover: Grounded mathematical proof generation with language models},
  author = {S Welleck, J Liu, X Lu, H Hajishirzi…},
  journal = {Advances in Neural …, 2022},
  publisher = {proceedings.neurips.cc},
  abstract = {… analogous to recent work on language modeling for formal theorem proving [32], where 
current models are typically limited to chaining 2 or 3 non-trivial steps of mathematical reasoning…},
  url = {https://proceedings.neurips.cc/paper_files/paper/2022/hash/1fc548a8243ad06616eee731e0572927-Abstract-Conference.html},
  note = {Retrieved from Google Scholar}
}

@article{LeastUnknownb,
  title = {Least-to-most prompting enables complex reasoning in large language models},
  author = {D Zhou, N Schärli, L Hou, J Wei, N Scales…},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {arxiv.org},
  abstract = {… Our empirical findings, which encompass symbolic manipulation, compositional generalization, 
and mathematical reasoning, reveal that least-to-most prompting significantly surpasses …},
  url = {https://arxiv.org/abs/2205.10625},
  note = {Retrieved from Google Scholar}
}

@article{LilaUnknownb,
  title = {Lila: A unified benchmark for mathematical reasoning},
  author = {S Mishra, M Finlayson, P Lu, L Tang, S Welleck…},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {arxiv.org},
  abstract = {… of much larger models (≈175B), to better understand the performance of the smaller trained 
models (≈2.7B) and to provide a benchmark for evaluating other large language models. …},
  url = {https://arxiv.org/abs/2210.17517},
  note = {Retrieved from Google Scholar}
}

@article{ProgramUnknownb,
  title = {Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks},
  author = {W Chen, X Ma, X Wang, WW Cohen},
  journal = {arXiv preprint arXiv:2211.12588, 2022},
  publisher = {arxiv.org},
  abstract = {… 4.1 Mathematical Reasoning in NLP Mathematical reasoning skills are essential for general-… 
Codet5+: Open code large language models for code understanding and generation. arXiv …},
  url = {https://arxiv.org/abs/2211.12588},
  note = {Retrieved from Google Scholar}
}

@article{StarUnknownb,
  title = {Star: Bootstrapping reasoning with reasoning},
  author = {E Zelikman, Y Wu, J Mu…},
  journal = {Advances in Neural …, 2022},
  publisher = {proceedings.neurips.cc},
  abstract = {… for LLMs across diverse tasks including mathematical reasoning, commonsense reasoning, 
… works has emerged exploring the capacity for large language models to perform in-context …},
  url = {https://proceedings.neurips.cc/paper_files/paper/2022/hash/639a9a172c044fbb64175b5fad42e9a5-Abstract-Conference.html},
  note = {Retrieved from Google Scholar}
}

@article{MrklUnknownb,
  title = {MRKL Systems: A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning},
  author = {E Karpas, O Abend, Y Belinkov, B Lenz…},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {arxiv.org},
  abstract = {… And mathematical reasoning is just the tip of an iceberg. … Despite all these shortcomings, 
large language models are an essential backbone of any future AI system. So the question is …},
  url = {https://arxiv.org/abs/2205.00445},
  note = {Retrieved from Google Scholar}
}

@article{LanguageUnknownb,
  title = {Language models are greedy reasoners: A systematic formal analysis of chain-of-thought},
  author = {A Saparov, H He},
  journal = {arXiv preprint arXiv:2210.01240, 2022},
  publisher = {arxiv.org},
  abstract = {… Large language models (LLMs) have shown remarkable … downstream tasks such as 
mathematical reasoning. However, … of that of general mathematical reasoning. Mathematical …},
  url = {https://arxiv.org/abs/2210.01240},
  note = {Retrieved from Google Scholar}
}

@article{EvaluatingUnknownb,
  title = {Evaluating transformer language models on arithmetic operations using number decomposition},
  author = {M Muffo, A Cocco, E Bertino},
  journal = {Proceedings of the Thirteenth …, 2022},
  publisher = {aclanthology.org},
  abstract = {… Abstract In recent years, Large Language Models such as GPT-3 showed remarkable … 
the tasks analysed, suggesting that there is large room for improving mathematical reasoning …},
  url = {https://aclanthology.org/2022.lrec-1.30/},
  note = {Retrieved from Google Scholar}
}

@article{WhatUnknown,
  title = {What do large language models learn beyond language?},
  author = {A Madasu, S Srivastava},
  journal = {arXiv preprint arXiv:2210.12302, 2022},
  publisher = {arxiv.org},
  abstract = {… Large language models (LMs) have rapidly become a mainstay in Natural Language Processing. … 
Further, previous methods explore mathematical reasoning tasks posed as language …},
  url = {https://arxiv.org/abs/2210.12302},
  note = {Retrieved from Google Scholar}
}

@article{LanguageUnknownc,
  title = {Language models show human-like content effects on reasoning},
  author = {I Dasgupta, AK Lampinen, SCY Chan…},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {stanford.edu},
  abstract = {… More recently, large language models have been similarly shown to accurately predict 
neural representations in the human language system — large language models “predict nearly …},
  url = {http://web.stanford.edu/~jlmcc/papers/DasguptaLampinenEtAl22LMsShowHumanLikeContentEffectsInReasoning.pdf},
  note = {Retrieved from Google Scholar}
}

@article{StructuredUnknown,
  title = {Structured, flexible, and robust: benchmarking and improving large language models towards more human-like behavior in out-of-distribution reasoning tasks},
  author = {KM Collins, C Wong, J Feng, M Wei…},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {arxiv.org},
  abstract = {… Our results in Part I suggest that even very large language models may not capture the 
characteristic flexibility of human reasoning: they struggle to produce language reflecting novel …},
  url = {https://arxiv.org/abs/2205.05718},
  note = {Retrieved from Google Scholar}
}

@article{DynamicUnknown,
  title = {Dynamic prompt learning via policy gradient for semi-structured mathematical reasoning},
  author = {P Lu, L Qiu, KW Chang, YN Wu, SC Zhu…},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {arxiv.org},
  abstract = {… system needs to perform mathematical reasoning over multi-… that requires mathematical 
reasoning over heterogeneous … mathematical reasoning and tabular context are necessary. …},
  url = {https://arxiv.org/abs/2209.14610},
  note = {Retrieved from Google Scholar}
}

@article{TeachingUnknown,
  title = {Teaching algorithmic reasoning via in-context learning},
  author = {H Zhou, A Nova, H Larochelle, A Courville…},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {arxiv.org},
  abstract = {… Large language models (LLMs) have shown increasing in-context learning capabilities … In 
this approach, we utilize one model for performing the informal mathematical reasoning steps …},
  url = {https://arxiv.org/abs/2211.09066},
  note = {Retrieved from Google Scholar}
}

@article{OvercomingUnknown,
  title = {Overcoming barriers to skill injection in language modeling: Case study in arithmetic},
  author = {M Sharma, N Muralidhar, N Ramakrishnan},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {arxiv.org},
  abstract = {… that also happens to be proficient in mathematical reasoning is not as straight-forward as … 
inherent numerical skills induced in large language models through unsupervised training [23, …},
  url = {https://arxiv.org/abs/2211.02098},
  note = {Retrieved from Google Scholar}
}

@article{LanguageUnknownd,
  title = {Language models of protein sequences at the scale of evolution enable accurate structure prediction},
  author = {Z Lin, H Akin, R Rao, B Hie, Z Zhu, W Lu…},
  journal = {BioRxiv, 2022},
  publisher = {biorxiv.org},
  abstract = {… Large language models have recently been shown to develop emergent capabilities with … 
-shot language translation, commonsense reasoning, and mathematical reasoning (11–14). To …},
  url = {https://www.biorxiv.org/content/10.1101/2022.07.20.500902v1.full.pdf?utm_campaign=M2D2%20Community%20Round-Up&utm_medium=email&utm_source=Revue%20newsletter},
  note = {Retrieved from Google Scholar}
}

@article{FormalUnknown,
  title = {Formal premise selection with language models},
  author = {Y Wu},
  journal = {Conference on Artificial Intelligence and Theorem …, 2022},
  publisher = {aitp},
  abstract = {… Program synthesis with large language models, 2021. … Evaluating large language models 
trained on code, 2021. … Isarstep: a benchmark for high-level mathematical reasoning. In …},
  url = {http://aitp-conference.org/2022/abstract/AITP_2022_paper_32.pdf},
  note = {Retrieved from Google Scholar}
}

@article{CausalguardUnknown,
  title = {CausalGuard: A Smart System for Detecting and Preventing False Information in Large Language Models},
  author = {P Patel},
  journal = {2022},
  publisher = {researchgate.net},
  abstract = {… While large language models have transformed … Mathematical Reasoning: While showing 
improvement over baselines on GSM8K (83.5%) and MATH (79.2%), mathematical reasoning …},
  url = {https://www.researchgate.net/profile/Piyushkumar-Patel-4/publication/397207990_CausalGuard_A_Smart_System_for_Detecting_and_Preventing_False_Information_in_Large_Language_Models/links/6908e0eea404d65709a2146d/CausalGuard-A-Smart-System-for-Detecting-and-Preventing-False-Information-in-Large-Language-Models.pdf},
  note = {Retrieved from Google Scholar}
}

@article{ThorUnknown,
  title = {Thor: Wielding hammers to integrate language models and automated theorem provers},
  author = {AQ Jiang, W Li, S Tworkowski…},
  journal = {Advances in …, 2022},
  publisher = {proceedings.neurips.cc},
  abstract = {In theorem proving, the task of selecting useful premises from a large library to unlock the 
proof of a given conjecture is crucially important. This presents a challenge for all theorem …},
  url = {https://proceedings.neurips.cc/paper_files/paper/2022/hash/377c25312668e48f2e531e2f2c422483-Abstract-Conference.html},
  note = {Retrieved from Google Scholar}
}

@article{LearnUnknownb,
  title = {Learn to Select Good Examples with Reinforcement Learning for Semi-structured Mathematical Reasoning},
  author = {P Lu, L Qiu, KW Chang, YN Wu, SC Zhu, T Rajpurohit…},
  journal = {mathai2022.github.io},
  abstract = {… remarkable progress on mathematical reasoning tasks written … problems that require 
mathematical reasoning on both textual … mathematical reasoning and tabular context are …},
  url = {https://mathai2022.github.io/papers/12.pdf},
  note = {Retrieved from Google Scholar}
}

@article{ReviewUnknown,
  title = {A review on language models as knowledge bases},
  author = {B AlKhamissi, M Li, A Celikyilmaz, M Diab…},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {arxiv.org},
  abstract = {Recently, there has been a surge of interest in the NLP community on the use of pretrained 
Language Models (LMs) as Knowledge Bases (KBs). Researchers have shown that LMs …},
  url = {https://arxiv.org/abs/2204.06031},
  note = {Retrieved from Google Scholar}
}

@article{LearningUnknown,
  title = {Learning to reason with relational abstractions},
  author = {AJ Nam, M Ren, C Finn, JL McClelland},
  journal = {arXiv preprint arXiv:2210.02615, 2022},
  publisher = {arxiv.org},
  abstract = {… Large language models have recently shown promising progress in mathematical reasoning 
when … how language models perform on tasks requiring multi-step mathematical reasoning. …},
  url = {https://arxiv.org/abs/2210.02615},
  note = {Retrieved from Google Scholar}
}

@article{LearnUnknownc,
  title = {Learn to explain: Multimodal reasoning via thought chains for science question answering},
  author = {P Lu, S Mishra, T Xia, L Qiu…},
  journal = {Advances in …, 2022},
  publisher = {proceedings.neurips.cc},
  abstract = {… Instead, we find that CoT can help large language models not only in the few-shot learning 
setting but also in the fine-tuning setting. When combined with CoT to generate the lecture …},
  url = {https://proceedings.neurips.cc/paper_files/paper/2022/hash/11332b6b6cf4485b84afadb1352d3a9a-Abstract-Conference.html},
  note = {Retrieved from Google Scholar}
}

@article{Proofnet2022b,
  title = {ProofNet: A benchmark for autoformalizing and formally proving undergraduate-level mathematics problems},
  author = {Z Azerbayev, B Piotrowski…},
  year = {2022},
  journal = {Second MATH},
  publisher = {AI …, 2022},
  abstract = {… has been to treat mathematical reasoning in natural language as … A key advantage of 
mathematical reasoning in natural … We have shown that pre-trained large language models …},
  url = {https://mathai2022.github.io/papers/20.pdf},
  note = {Retrieved from Google Scholar}
}

@article{ImpactUnknown,
  title = {Impact of pretraining term frequencies on few-shot reasoning},
  author = {Y Razeghi, RL Logan IV, M Gardner…},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {arxiv.org},
  abstract = {… the reasoning evaluation schemes for the large language models. Further characterizing the 
… should not treat the pretraining data of the large language models as unknown black boxes. …},
  url = {https://arxiv.org/abs/2202.07206},
  note = {Retrieved from Google Scholar}
}

@article{CognitiveUnknown,
  title = {Cognitive Architectures for Explainable AI: Integrating Chain-of-Thought Reasoning in LLMs},
  author = {H Ahmad, M Daviglus},
  journal = {2022},
  publisher = {researchgate.net},
  abstract = {… As large language models (LLMs) become increasingly … Thought (CoT) reasoning in large 
language models (LLMs) has … logical inference, mathematical reasoning, and structured …},
  url = {https://www.researchgate.net/profile/Mendus-Daviglus/publication/388835264_Cognitive_Architectures_for_Explainable_AI_Integrating_Chain-of-_Thought_Reasoning_in_LLMs/links/67a908be4c479b26c9db9a3e/Cognitive-Architectures-for-Explainable-AI-Integrating-Chain-of-Thought-Reasoning-in-LLMs.pdf},
  note = {Retrieved from Google Scholar}
}

@article{OutofUnknown,
  title = {Outof-distribution generalization in algorithmic reasoning through curriculum learning},
  author = {AJ Nam, M Abdool, T Maxfield…},
  journal = {CoRR abs …, 2022},
  publisher = {mathai2022.github.io},
  abstract = {… Large transformer-based ‘foundation’ models [1] have attracted recent attention by showing 
some success in mathematical reasoning tasks, demonstrating a degree of systematicity and …},
  url = {https://mathai2022.github.io/papers/22.pdf},
  note = {Retrieved from Google Scholar}
}

@article{DraftUnknown,
  title = {Draft, sketch, and prove: Guiding formal theorem provers with informal proofs},
  author = {AQ Jiang, S Welleck, JP Zhou, W Li, J Liu…},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {arxiv.org},
  abstract = {… We hypothesize that this technique is beneficial for large language models to synthesize 
formal sketches. To validate this hypothesis, we perform an ablation study by removing the in-…},
  url = {https://arxiv.org/abs/2210.12283},
  note = {Retrieved from Google Scholar}
}

@article{QuestionUnknown,
  title = {Is a question decomposition unit all we need?},
  author = {P Patel, S Mishra, M Parmar, C Baral},
  journal = {arXiv preprint arXiv:2205.12538, 2022},
  publisher = {arxiv.org},
  abstract = {… Large Language Models (LMs) have achieved state-of-the-art performance on many Natu… 
Numglue: A suite of fundamental yet challenging mathematical reasoning tasks. In …},
  url = {https://arxiv.org/abs/2205.12538},
  note = {Retrieved from Google Scholar}
}

@article{MindUnknown,
  title = {Mind's eye: Grounded language model reasoning through simulation},
  author = {R Liu, J Wei, SS Gu, TY Wu, S Vosoughi, C Cui…},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {arxiv.org},
  abstract = {… This setting is also different from those in mathematical reasoning tasks (eg, GSM8k (Cobbe … 
Chain of thought prompting elicits reasoning in large language models. Conference on …},
  url = {https://arxiv.org/abs/2210.05359},
  note = {Retrieved from Google Scholar}
}

@article{BranchUnknown,
  title = {Branch-train-merge: Embarrassingly parallel training of expert language models},
  author = {M Li, S Gururangan, T Dettmers, M Lewis…},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {arxiv.org},
  abstract = {… We present Branch-Train-Merge (BTM), a communication-efficient algorithm for 
embarrassingly parallel training of large language models (LLMs). We show it is possible to …},
  url = {https://arxiv.org/abs/2208.03306},
  note = {Retrieved from Google Scholar}
}

@article{ComposingUnknown,
  title = {Composing ensembles of pre-trained models via iterative consensus},
  author = {S Li, Y Du, JB Tenenbaum, A Torralba…},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {arxiv.org},
  abstract = {… method can be used as a general purpose framework for a wide range of zero-shot 
multimodal tasks, such as image generation, video question answering, mathematical reasoning, …},
  url = {https://arxiv.org/abs/2210.11522},
  note = {Retrieved from Google Scholar}
}

@article{LanguageUnknowne,
  title = {Language models are general-purpose interfaces},
  author = {Y Hao, H Song, L Dong, S Huang, Z Chi…},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {arxiv.org},
  abstract = {Foundation models have received much attention due to their effectiveness across a broad 
range of downstream applications. Though there is a big convergence in terms of architecture…},
  url = {https://arxiv.org/abs/2206.06336},
  note = {Retrieved from Google Scholar}
}

@article{VeryUnknown,
  title = {Very large language model as a unified methodology of text mining},
  author = {M Jiang},
  journal = {arXiv preprint arXiv:2212.09271, 2022},
  publisher = {arxiv.org},
  abstract = {… on story writing, question answering, or mathematical reasoning just by conditioning on input-… 
Generate rather than retrieve: Large language models are strong context generators. arXiv …},
  url = {https://arxiv.org/abs/2212.09271},
  note = {Retrieved from Google Scholar}
}

@article{LanguageUnknownf,
  title = {Language models can teach themselves to program better},
  author = {P Haluptzok, M Bowers, AT Kalai},
  journal = {arXiv preprint arXiv:2207.14502, 2022},
  publisher = {arxiv.org},
  abstract = {Recent Language Models (LMs) achieve breakthrough performance in code generation 
when trained on human-authored problems, even solving some competitive-programming …},
  url = {https://arxiv.org/abs/2207.14502},
  note = {Retrieved from Google Scholar}
}

@article{ProceedingsUnknown,
  title = {Proceedings of the 2nd Workshop on Natural Language Generation, Evaluation, and Metrics (GEM)},
  author = {A Bosselut, K Chandu, K Dhole, V Gangal…},
  journal = {Proceedings of the …, 2022},
  publisher = {aclanthology.org},
  abstract = {… Abstract: While research on large language models (LLMs) … door to tackling challenging 
mathematical reasoning tasks. Join me … focus on mathematical reasoning. He received his Ph.D. …},
  url = {https://aclanthology.org/2022.gem-1.0.pdf},
  note = {Retrieved from Google Scholar}
}

@article{TextUnknown,
  title = {Text and patterns: For effective chain of thought, it takes two to tango},
  author = {A Madaan, A Yazdanbakhsh},
  journal = {arXiv preprint arXiv:2209.07686, 2022},
  publisher = {arxiv.org},
  abstract = {… an unprecedented scaling of large language models. These … pushes the performance of 
large language models in a few-… tasks and across three large language models—PaLM, GPT-…},
  url = {https://arxiv.org/abs/2209.07686},
  note = {Retrieved from Google Scholar}
}

@article{GeneratingUnknown,
  title = {Generating sequences by learning to self-correct},
  author = {S Welleck, X Lu, P West, F Brahman, T Shen…},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {arxiv.org},
  abstract = {… the promise of using (self-)correctors for controlling the outputs of large language models. … 
Chain of thought prompting elicits reasoning in large language models. ArXiv, abs/2201.11903…},
  url = {https://arxiv.org/abs/2211.00053},
  note = {Retrieved from Google Scholar}
}

@article{Exploring2022c,
  title = {Exploring Communicative Strategies for Dual LLM Agents in Mathematical Problem Solving},
  author = {L Zhang, J Lin, X Zhai, D Zapata},
  year = {2022},
  journal = {Rivera, C Forsyth…},
  publisher = {2022},
  abstract = {… The advancement of multi-agent workflows leveraging Large Language Models (LLMs) 
for tackling complex tasks, such as mathematical problem-solving, has garnered significant …},
  url = {https://www.researchgate.net/profile/Liang-Zhang-10/publication/390466024_Exploring_Communicative_Strategies_for_Dual_LLM_Agents_in_Mathematical_Problem_Solving/links/67eeea71e8041142a161472a/Exploring-Communicative-Strategies-for-Dual-LLM-Agents-in-Mathematical-Problem-Solving.pdf},
  note = {Retrieved from Google Scholar}
}

@article{MemorizingUnknown,
  title = {Memorizing transformers},
  author = {Y Wu, MN Rabe, DL Hutchins, C Szegedy},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {arxiv.org},
  abstract = {… The simplicity of the changes to the Transformer architecture allows us to easily integrate 
this approach into existing code bases, including extremely large language models. We further …},
  url = {https://arxiv.org/abs/2203.08913},
  note = {Retrieved from Google Scholar}
}

@article{NeuralUnknown,
  title = {A neural network solves, explains, and generates university math problems by program synthesis and few-shot learning at human level},
  author = {I Drori, S Zhang, R Shuttleworth, L Tang, A Lu…},
  journal = {Proceedings of the …, 2022},
  publisher = {pnas.org},
  abstract = {… and Probability, Intermediate Algebra, Number Theory, and Precalculus), the latest 
benchmark of advanced mathematics problems designed to assess mathematical reasoning. We …},
  url = {https://www.pnas.org/doi/abs/10.1073/pnas.2123433119},
  note = {Retrieved from Google Scholar}
}

@article{NumericalUnknown,
  title = {Numerical Correlation in Text},
  author = {D Spokoyny, CS Wu, C Xiong},
  journal = {Proceedings of the 1st Workshop …, 2022},
  publisher = {aclanthology.org},
  abstract = {… Evaluation of quantitative reasoning of large language models is an important step towards 
understanding their current capabilities and limitations. We propose a new task, Numerical …},
  url = {https://aclanthology.org/2022.mathnlp-1.5/},
  note = {Retrieved from Google Scholar}
}

@article{AchievingUnknown,
  title = {Achieving and Understanding Out-of-Distribution Generalization in Systematic Reasoning in Small-Scale Transformers},
  author = {AJ Nam, M Abdool, T Maxfield…},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {arxiv.org},
  abstract = {… by showing some success in mathematical reasoning tasks, demonstrating a degree of … 
of large transformer-based models, especially in large language models such as GPT-3 [3] …},
  url = {https://arxiv.org/abs/2210.03275},
  note = {Retrieved from Google Scholar}
}

@article{FormalUnknownb,
  title = {Formal specifications from natural language},
  author = {C Hahn, F Schmitt, JJ Tillman, N Metzger…},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {arxiv.org},
  abstract = {We study the generalization abilities of language models when translating natural language 
into formal specifications with complex semantics. In particular, we fine-tune language …},
  url = {https://arxiv.org/abs/2206.01962},
  note = {Retrieved from Google Scholar}
}

@article{CorrectnessUnknown,
  title = {Correctness Comparison of ChatGPT-4, Bard, Claude-2, and Copilot for Spatial Tasks. 2},
  author = {HH Hochmaira, L Juhászb, T Kempa},
  journal = {2022},
  publisher = {researchgate.net},
  abstract = {… Generative AI including large language models (LLMs) have recently gained significant … 
, while Claude-2 demonstrates strengths in mathematical reasoning (Barilla, 2023). Bard AI is …},
  url = {https://www.researchgate.net/profile/Levente-Juhasz/publication/377178667_Correctness_Comparison_of_ChatGPT-4_Gemini_Claude-3_and_Copilot_for_Spatial_Tasks/links/659821c80bb2c7472b361688/Correctness-Comparison-of-ChatGPT-4-Gemini-Claude-3-and-Copilot-for-Spatial-Tasks.pdf},
  note = {Retrieved from Google Scholar}
}

@article{MileUnknownb,
  title = {MILE: Memory-Interactive Learning Engine for Solving Mathematical Problems},
  author = {Y Wu, H Nakayama},
  journal = {openreview.net},
  abstract = {… Mathematical reasoning is a field quite suitable for this study because of its high-level … 
Prompt programming for large language models: Beyond the few-shot paradigm. In Extended …},
  url = {https://openreview.net/forum?id=nQtcJ24_45K},
  note = {Retrieved from Google Scholar}
}

@article{StarUnknownc,
  title = {Star: Self-taught reasoner},
  author = {E Zelikman, Y Wu…},
  journal = {Proceedings of the …, 2022},
  publisher = {raw.githubusercontent.com},
  abstract = {… ” for intermediate steps, large language models (LLMs) can … range of tasks including 
mathematical reasoning, commonsense … In addition, as text generation by large language models …},
  url = {https://raw.githubusercontent.com/labmlai/annotated_deep_learning_paper_implementations/master/papers/2203.14465.pdf},
  note = {Retrieved from Google Scholar}
}

@article{MultiUnknown,
  title = {Multi-lingual evaluation of code generation models},
  author = {B Athiwaratkun, SK Gouda, Z Wang, X Li, Y Tian…},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {arxiv.org},
  abstract = {… models on complex context, which requires mathematical reasoning. Similar to Section 4.4 
and … More recently, various work have been proposed to use large language models for code …},
  url = {https://arxiv.org/abs/2210.14868},
  note = {Retrieved from Google Scholar}
}

@article{ParallelUnknown,
  title = {A parallel corpus of natural language and isabelle artefacts},
  author = {A Bordg, YA Stathopoulos…},
  journal = {7th Conference on …, 2022},
  publisher = {aitp},
  abstract = {… Evaluating large language models trained on code. 2021. … Mathematical reasoning via 
self-supervised skip-tree training. In International Conference on Learning Representations, 2021…},
  url = {http://aitp-conference.org/2022/abstract/AITP_2022_paper_8.pdf},
  note = {Retrieved from Google Scholar}
}

@article{ImpactUnknownb,
  title = {The impact of symbolic representations on in-context learning for few-shot reasoning},
  author = {H Zhang, YF Zhang, LE Li, E Xing},
  journal = {NeurIPS 2022 Workshop on …, 2022},
  publisher = {openreview.net},
  abstract = {… Chain of thought prompting elicits reasoning in large language models. arXiv preprint 
arXiv:… Least-to-most prompting enables complex reasoning in large language models. arXiv …},
  url = {https://openreview.net/forum?id=qLgQpeQX3x1},
  note = {Retrieved from Google Scholar}
}

@article{TeachingUnknownb,
  title = {Teaching broad reasoning skills for multi-step QA by generating hard contexts},
  author = {H Trivedi, N Balasubramanian, T Khot…},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {arxiv.org},
  abstract = {… Our experiments demonstrate that pretraining3 large language models (LMs) on TEABREAC 
before fine-tuning on target multi-step QA datasets results in significant improvements on …},
  url = {https://arxiv.org/abs/2205.12496},
  note = {Retrieved from Google Scholar}
}

@article{LogicalUnknown,
  title = {Logical tasks for measuring extrapolation and rule comprehension},
  author = {I Fujisawa, R Kanai},
  journal = {arXiv preprint arXiv:2211.07727, 2022},
  publisher = {arxiv.org},
  abstract = {… There are no reliable large language models to do this with symbolic operations. GPT-3 
fails to solve elementary arithmetic equations. It works well on twodigit addition, but accuracy …},
  url = {https://arxiv.org/abs/2211.07727},
  note = {Retrieved from Google Scholar}
}

@article{SurveyUnknown,
  title = {A survey in mathematical language processing},
  author = {J Meadows, A Freitas},
  journal = {arXiv preprint arXiv:2205.15231, 2022},
  publisher = {arxiv.org},
  abstract = {… Delivering mathematical reasoning over discourse requires close integration between 
step-wise inference control over localised explicit representations (symbolic perspective), and dis…},
  url = {https://arxiv.org/abs/2205.15231},
  note = {Retrieved from Google Scholar}
}

@article{UnveilingUnknown,
  title = {Unveiling transformers with lego: a synthetic reasoning task},
  author = {Y Zhang, A Backurs, S Bubeck, R Eldan…},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {arxiv.org},
  abstract = {We propose a synthetic reasoning task, LEGO (Learning Equality and Group Operations), 
that encapsulates the problem of following a chain of reasoning, and we study how the …},
  url = {https://arxiv.org/abs/2206.04301},
  note = {Retrieved from Google Scholar}
}

@article{TeachingUnknownc,
  title = {Teaching Broad Reasoning Skills via Decomposition-Guided Contexts},
  author = {H Trivedi, N Balasubramanian, T Khot…},
  journal = {Proceedings of the 2022 …, 2022},
  publisher = {par.nsf.gov},
  abstract = {… Our experiments demonstrate that pretraining3 large language models (LMs) on TEABREAC 
before fine-tuning on target multi-step QA datasets results in significant improvements on …},
  url = {https://par.nsf.gov/biblio/10432871},
  note = {Retrieved from Google Scholar}
}

@article{ProgramUnknownc,
  title = {Program synthesis for integer sequence generation},
  author = {N Butt, A Wiggers, T Cohen, M Welling},
  journal = {2022},
  publisher = {mathai2022.github.io},
  abstract = {Recent advances in program synthesis have shown success with methods that employ 
supervised learning on synthetic data generated from domain specific languages (DSLs). In this …},
  url = {https://mathai2022.github.io/papers/24.pdf},
  note = {Retrieved from Google Scholar}
}

@article{AutomaticallyUnknown,
  title = {Automatically answering and generating machine learning final exams},
  author = {S Zhang, RS Shuttleworth, Z Chin, P Lantigua…},
  journal = {2022},
  publisher = {openreview.net},
  abstract = {… We use the latest OpenAI GPT-3 and Codex models and do not re-train these very large 
language models. We fix all the hyperparameters of the models so that the answers are …},
  url = {https://openreview.net/forum?id=MT1Pcdo8sGG},
  note = {Retrieved from Google Scholar}
}

@article{AlgorithmicUnknown,
  title = {Algorithmic Dimensions, the Point-To-Set Principles, and the Complexity of Oracles},
  author = {E Mayordomo Cámara},
  journal = {2022},
  publisher = {zaguan.unizar.es},
  abstract = {… With the advent of the “golden age of Natural Language Processing” [1] (NLP), a contagious 
enthusiasm on the capabilities of large language models (LLMs) started spreading from …},
  url = {https://zaguan.unizar.es/record/121866},
  note = {Retrieved from Google Scholar}
}

@article{JrirdUnknown,
  title = {JRIRD at the NTCIR-16 FinNum-3 Task: Investigating the Effect of Numerical Representations in Manager's Claim Detection},
  author = {S Onuma, K Kadowaki},
  journal = {… of the 16th NTCIR Conference on …, 2022},
  publisher = {research.nii.ac.jp},
  abstract = {… However, the performance of large language models worsened in some formats. … 
Mathematical Reasoning in General Artificial Intelligence Workshop at ICLR 2021. …},
  url = {https://research.nii.ac.jp/ntcir/workshop/OnlineProceedings16/pdf/ntcir/05-NTCIR16-FINNUM-OnumaS.pdf},
  note = {Retrieved from Google Scholar}
}

@article{TowardsUnknownb,
  title = {Towards data-and knowledge-driven artificial intelligence: A survey on neuro-symbolic computing},
  author = {W Wang, Y Yang, F Wu},
  journal = {arXiv preprint arXiv:2210.15889, 2022},
  publisher = {arxiv.org},
  abstract = {… diagnosis, autonomous driving, and mathematical reasoning, and lead to the increasing … 
NLP systems, including large language models like GPT3 [61], fall under this category (see …},
  url = {https://arxiv.org/abs/2210.15889},
  note = {Retrieved from Google Scholar}
}

@article{Sqa3dUnknown,
  title = {Sqa3d: Situated question answering in 3d scenes},
  author = {X Ma, S Yong, Z Zheng, Q Li, Y Liang, SC Zhu…},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {arxiv.org},
  abstract = {… Finally, we explore whether powerful Large Language Models (LLMs) like GPT-3 (Brown et 
al… Chain of thought prompting elicits reasoning in large language models. arXiv preprint arXiv:…},
  url = {https://arxiv.org/abs/2210.07474},
  note = {Retrieved from Google Scholar}
}

@article{InsideUnknown,
  title = {Inside the Mind of an AI: Materiality and the Crisis of Representation},
  author = {NK Hayles},
  journal = {New Literary History, 2022},
  publisher = {muse.jhu.edu},
  abstract = {… —also have cognitive capabilities, as do large language models [End Page 652] such as … 
be true, a tactic sometimes used in mathematical reasoning). However, it immediately qualifies …},
  url = {https://muse.jhu.edu/pub/1/article/898324/summary},
  note = {Retrieved from Google Scholar}
}

@article{MathematicalUnknown,
  title = {Mathematical proof between generations},
  author = {J Bayer, C Benzmüller, K Buzzard, M David, L Lamport…},
  journal = {2022},
  publisher = {ams.org},
  abstract = {… Another possibility is training large language models such as ChatGPT to write Lean code. 
… The idea of applying technology to mathematical reasoning began to be realized in the 1960s…},
  url = {https://www.ams.org/journals/notices/202401/rnoti-p79.pdf},
  note = {Retrieved from Google Scholar}
}

@article{MathematicalUnknownb,
  title = {Mathematical intelligence: what we have that machines don't},
  author = {J Mubeen},
  journal = {2022},
  publisher = {books.google.com},
  abstract = {… the confabulatory behaviours of large language models long before … Large language models 
set machines on a 'mindless' path … Large language models already depend a great deal on …},
  url = {https://books.google.com/books?hl=en&lr=&id=3-JBEAAAQBAJ&oi=fnd&pg=PT4&dq=%22large+language+models%22+%22mathematical+reasoning%22&ots=HMTZF9syfO&sig=rro66WG0rP_wX1bW5s50ZWWECH0},
  note = {Retrieved from Google Scholar}
}

@article{SomeUnknown,
  title = {Some representation learning tasks and the inspection of their models},
  author = {L Pfahler},
  journal = {2022},
  publisher = {eldorado.tu},
  abstract = {… Bender et al. demonstrate the dangers of training large language models on web crawls with 
little quality control [14], including how small diversity in the data can lead to discrimination, …},
  url = {https://eldorado.tu-dortmund.de/bitstream/2003/41168/1/dissertation.pdf},
  note = {Retrieved from Google Scholar}
}

@article{NeurosymbolicUnknown,
  title = {Neurosymbolic Machine Learning for Reasoning},
  author = {K Yang},
  journal = {2022},
  publisher = {search.proquest.com},
  abstract = {… Proof assistants offer a formalism that resembles human mathematical reasoning, representing 
theorems in higher-order logic and proofs as high-level tactics. However, human experts …},
  url = {https://search.proquest.com/openview/2ab78d5c4887ddfe4b34a1cde865a303/1?pq-origsite=gscholar&cbl=18750&diss=y},
  note = {Retrieved from Google Scholar}
}

@article{NaturalUnknown,
  title = {Natural language deduction through search over statement compositions},
  author = {K Bostrom, Z Sprague, S Chaudhuri…},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {arxiv.org},
  abstract = {In settings from fact-checking to question answering, we frequently want to know whether a 
collection of evidence (premises) entails a hypothesis. Existing methods primarily focus on …},
  url = {https://arxiv.org/abs/2201.06028},
  note = {Retrieved from Google Scholar}
}

@article{NeuroUnknown,
  title = {Is neuro-symbolic ai meeting its promise in natural language processing? a structured},
  author = {K Hamilton, A Nayak, B Božic, L Longo},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {academia.edu},
  abstract = {… , the success of the Transformer and Large Language Models (LLMs) has also served to … 
types of logic, human reasoning, and mathematical reasoning, as well as counter-productive …},
  url = {https://www.academia.edu/download/95152225/2202.12205.pdf},
  note = {Retrieved from Google Scholar}
}

@article{ExpertUnknown,
  title = {A non-expert's introduction to data ethics for mathematicians},
  author = {MA Porter},
  journal = {2022},
  publisher = {books.google.com},
  abstract = {… There are significant risks and potential nefarious uses of tools like generative AI and large 
language models (LLMs) [ BGMMS21 , EMFG+22 , Fer24 ]. Modern data analysis also has …},
  url = {https://books.google.com/books?hl=en&lr=&id=fNhcEQAAQBAJ&oi=fnd&pg=PA65&dq=%22large+language+models%22+%22mathematical+reasoning%22&ots=ttLO9dhMOq&sig=zyld8LsSu1IvvZLqW1NsNBySmPw},
  note = {Retrieved from Google Scholar}
}

@article{TowardsUnknownc,
  title = {Towards neuro-symbolic conjecturing},
  author = {SH Einarsdóttir, M Johansson, N Smallbone},
  journal = {aitp},
  publisher = {conference.org},
  abstract = {… There have been recent attempts to use large language models for conjecturing tasks [8… 
Mathematical reasoning via self-supervised skiptree training. In Proceedings of ICLR, 2021. …},
  url = {http://aitp-conference.org/2022/abstract/AITP_2022_paper_13.pdf},
  note = {Retrieved from Google Scholar}
}

@article{OpenUnknown,
  title = {Open-Ended Knowledge Tracing},
  author = {N Liu, Z Wang, RG Baraniuk…},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {people.umass.edu},
  abstract = {ABSTRACT Knowledge tracing refers to the problem of estimating each student’s knowledge 
component/skill mastery level from their past responses to questions in educational …},
  url = {https://people.umass.edu/~andrewlan/papers/preprint-OKT.pdf},
  note = {Retrieved from Google Scholar}
}

@article{ExploringUnknown,
  title = {Exploring the landscape of distributional robustness for question answering models},
  author = {A Awadalla, M Wortsman, G Ilharco, S Min…},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {arxiv.org},
  abstract = {… This is particularly useful for very large language models, where fine-tuning is expensive. 
In-context learning refers to the process of conditioning a language model on one or more …},
  url = {https://arxiv.org/abs/2210.12517},
  note = {Retrieved from Google Scholar}
}

@article{MachineUnknown,
  title = {Machine learning and logic: a new frontier in artificial intelligence},
  author = {V Ganesh, SA Seshia, S Jha},
  journal = {Formal Methods in System Design, 2022},
  publisher = {Springer},
  abstract = {Abstract Machine learning and logical reasoning have been the two foundational pillars of 
Artificial Intelligence (AI) since its inception, and yet, until recently the interactions between …},
  url = {https://link.springer.com/article/10.1007/s10703-023-00430-1},
  note = {Retrieved from Google Scholar}
}

@article{TransformersUnknown,
  title = {Transformers learn shortcuts to automata},
  author = {B Liu, JT Ash, S Goel, A Krishnamurthy…},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {arxiv.org},
  abstract = {Algorithmic reasoning requires capabilities which are most naturally understood through 
recurrent models of computation, like the Turing machine. However, Transformer models, while …},
  url = {https://arxiv.org/abs/2210.10749},
  note = {Retrieved from Google Scholar}
}

@article{LearningUnknownb,
  title = {Learning to Discover Proofs and Theorems Without Supervision},
  author = {J Laurent},
  journal = {2022},
  publisher = {cs.cmu.edu},
  abstract = {… However, despite impressive progress involving large language models [11] and self-… 
The main computational obstacle to using large language models with our framework is the …},
  url = {https://www.cs.cmu.edu/~jlaurent/pdf/reports/thesis-proposal.pdf},
  note = {Retrieved from Google Scholar}
}

@article{InsightsUnknown,
  title = {Insights into pre-training via simpler synthetic tasks},
  author = {Y Wu, F Li, PS Liang},
  journal = {Advances in Neural Information …, 2022},
  publisher = {proceedings.neurips.cc},
  abstract = {Pre-training produces representations that are effective for a wide range of downstream 
tasks, but it is still unclear what properties of pre-training are necessary for effective gains. …},
  url = {https://proceedings.neurips.cc/paper_files/paper/2022/hash/89379d5fc6eb34ff98488202fb52b9d0-Abstract-Conference.html},
  note = {Retrieved from Google Scholar}
}

@article{InformsUnknown,
  title = {Law informs code: A legal informatics approach to aligning artificial intelligence with humans},
  author = {JJ Nay},
  journal = {Nw. J. Tech. & Intell. Prop., 2022},
  publisher = {HeinOnline},
  abstract = {Artificial Intelligence (AI) capabilities are rapidly advancing. Highly capable Al could cause 
radically different futures depending on how it is developed and deployed. We are unable to …},
  url = {https://heinonline.org/hol-cgi-bin/get_pdf.cgi?handle=hein.journals/nwteintp20&section=14},
  note = {Retrieved from Google Scholar}
}

@article{GatheringUnknown,
  title = {Gathering strength, gathering storms: The one hundred year study on artificial intelligence (AI100) 2021 study panel report},
  author = {ML Littman, I Ajunwa, G Berger, C Boutilier…},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {arxiv.org},
  abstract = {… Spotify’s use of audio analysis of music40 or the application of large language models … 
.org/how-close-are-computers-to-automating-mathematical-reasoning-20200827/ …},
  url = {https://arxiv.org/abs/2210.15767},
  note = {Retrieved from Google Scholar}
}

@article{StateUnknown,
  title = {State-of-the-art generalisation research in NLP: a taxonomy and review},
  author = {D Hupkes, M Giulianelli, V Dankers, M Artetxe…},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {arxiv.org},
  abstract = {… of study using very large language models: the computational … the evaluation data of large 
language models makes it hard to … also be conducted with large language models but the lack …},
  url = {https://arxiv.org/abs/2210.03050},
  note = {Retrieved from Google Scholar}
}

@article{AttentionUnknown,
  title = {Attention flows for general transformers},
  author = {N Metzger, C Hahn, J Siber, F Schmitt…},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {arxiv.org},
  abstract = {In this paper, we study the computation of how much an input token in a Transformer model 
influences its prediction. We formalize a method to construct a flow network out of the …},
  url = {https://arxiv.org/abs/2205.15389},
  note = {Retrieved from Google Scholar}
}

@article{VisionUnknown,
  title = {Vision transformers provably learn spatial structure},
  author = {S Jelassi, M Sander, Y Li},
  journal = {Advances in Neural Information …, 2022},
  publisher = {proceedings.neurips.cc},
  abstract = {… 67] or in mathematical reasoning [73]. In this paper, we focus on computer vision where 
convolutions are considered to be an adequate and biologically plausible inductive bias since …},
  url = {https://proceedings.neurips.cc/paper_files/paper/2022/hash/f69707de866eb0805683d3521756b73f-Abstract-Conference.html},
  note = {Retrieved from Google Scholar}
}

@article{NeuralUnknownb,
  title = {Neural-symbolic recursive machine for systematic generalization},
  author = {Q Li, Y Zhu, Y Liang, YN Wu, SC Zhu…},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {arxiv.org},
  abstract = {… 2020), and large language models have been guided towards compositional semantic parsing 
on CFQ (Drozdov … Compositional semantic parsing with large language models. ICLR. 1…},
  url = {https://arxiv.org/abs/2210.01603},
  note = {Retrieved from Google Scholar}
}

@article{BoxbartUnknown,
  title = {In-boxbart: Get instructions into biomedical multi-task learning},
  author = {M Parmar, S Mishra, M Purohit, M Luo…},
  journal = {Findings of the …, 2022},
  publisher = {aclanthology.org},
  abstract = {Single-task models have proven pivotal in solving specific tasks; however, they have 
limitations in real-world applications where multi-tasking is necessary and domain shifts are …},
  url = {https://aclanthology.org/2022.findings-naacl.10/},
  note = {Retrieved from Google Scholar}
}

@article{SolvingUnknownc,
  title = {Solving probability and statistics problems by probabilistic program synthesis at human level and predicting solvability},
  author = {L Tang, E Ke, N Singh, B Feng, D Austin…},
  journal = {… Conference on Artificial …, 2022},
  publisher = {Springer},
  abstract = {We use probabilistic program synthesis to solve questions in MIT and Harvard Probability and 
Statistics courses. Traditional approaches using the latest GPT-3 language model without …},
  url = {https://link.springer.com/chapter/10.1007/978-3-031-11647-6_127},
  note = {Retrieved from Google Scholar}
}

@article{OptimizationUnknown,
  title = {Optimization and High-Dimensional Loss Landscapes in Deep Learning},
  author = {BW Larsen},
  journal = {2022},
  publisher = {search.proquest.com},
  abstract = {… (3) In the training of large language models, a common problem is that loss spikes and 
training becomes unstable. A hypothesis for why this phenomenon occurs is that the network is …},
  url = {https://search.proquest.com/openview/3ff627dbe318ef9a8a75d8f91e5773e7/1?pq-origsite=gscholar&cbl=18750&diss=y},
  note = {Retrieved from Google Scholar}
}

@article{TowardsUnknownd,
  title = {Towards learning universal hyperparameter optimizers with transformers},
  author = {Y Chen, X Song, C Lee, Z Wang…},
  journal = {Advances in …, 2022},
  publisher = {proceedings.neurips.cc},
  abstract = {Meta-learning hyperparameter optimization (HPO) algorithms from prior experiments is a 
promising approach to improve optimization efficiency over objective functions from a similar …},
  url = {https://proceedings.neurips.cc/paper_files/paper/2022/hash/cf6501108fced72ee5c47e2151c4e153-Abstract-Conference.html},
  note = {Retrieved from Google Scholar}
}

@article{LearningUnknownc,
  title = {Big Learning},
  author = {Y Cong, M Zhao},
  journal = {arXiv preprint arXiv:2207.03899, 2022},
  publisher = {arxiv.org},
  abstract = {Recent advances in big/foundation models reveal a promising path for deep learning, 
where the roadmap steadily moves from big data to big models to (the newly-introduced) big …},
  url = {https://arxiv.org/abs/2207.03899},
  note = {Retrieved from Google Scholar}
}

@article{RevolutionsUnknownb,
  title = {Revolutions and Revelations in Computability LNCS 13359},
  author = {U Berger, JNY Franklin, F Manea, A Pauly},
  journal = {Springer},
  abstract = {… With the advent of the “golden age of Natural Language Processing” [1] (NLP), a contagious 
enthusiasm on the capabilities of large language models (LLMs) started spreading from …},
  url = {https://link.springer.com/content/pdf/10.1007/978-3-031-08740-0.pdf},
  note = {Retrieved from Google Scholar}
}

@article{CitationUnknown,
  title = {[CITATION][C] Why code is more important than flat design},
  author = {A Blackwell},
  journal = {Moral Codes, 2022},
  publisher = {MIT Press},
  note = {Retrieved from Google Scholar}
}

@article{DatasheetUnknown,
  title = {Datasheet for the pile},
  author = {S Biderman, K Bicheno, L Gao},
  journal = {arXiv preprint arXiv:2201.07311, 2022},
  publisher = {arxiv.org},
  abstract = {This datasheet describes the Pile, a 825 GiB dataset of human-authored text compiled by 
EleutherAI for use in large-scale language modeling. The Pile is comprised of 22 different text …},
  url = {https://arxiv.org/abs/2201.07311},
  note = {Retrieved from Google Scholar}
}

@article{TowardsUnknowne,
  title = {Towards Multimodal, Interpretable and Robust Task-Oriented Dialogue Modeling},
  author = {S Yang},
  journal = {2022},
  publisher = {minerva},
  abstract = {… which contains about 150 different NLP tasks ranging from text classification, question 
answering, to more difficult tasks such as common sense reasoning and mathematical reasoning. …},
  url = {https://minerva-access.unimelb.edu.au/items/355cb5b3-66da-478d-95a3-7a8d4c28c3a9},
  note = {Retrieved from Google Scholar}
}

@article{SurveyUnknownb,
  title = {A Survey of Parameters Associated with the Quality of Benchmarks in NLP},
  author = {S Mishra, A Arunkumar, C Bryan, C Baral},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {arxiv.org},
  abstract = {… Numglue: A suite of fundamental yet challenging mathematical reasoning tasks. In Proceedings 
of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: …},
  url = {https://arxiv.org/abs/2210.07566},
  note = {Retrieved from Google Scholar}
}

@article{LearningUnknownd,
  title = {Big Learning: A Universal Machine Learning Paradigm?},
  author = {Y Cong, M Zhao},
  journal = {2022},
  publisher = {openreview.net},
  abstract = {Recent breakthroughs based on big/foundation models reveal a vague avenue for AI, that is, 
emphbig data, big/foundation models, big learning, $cdots$. Following that avenue, here …},
  url = {https://openreview.net/forum?id=UfFXUfAsnPH},
  note = {Retrieved from Google Scholar}
}

@article{RepairingUnknownb,
  title = {Repairing Circuits with Transformers},
  author = {M Cosler},
  journal = {finkbeiner.groups.cispa.de},
  abstract = {In this work, we present an approach for repairing faulty circuits using deep neural networks. 
Given a faulty circuit and a specification in LTL, we demonstrate that our approach repairs …},
  url = {https://finkbeiner.groups.cispa.de/publications/Cosler22.pdf},
  note = {Retrieved from Google Scholar}
}

@article{RevolutionsUnknownc,
  title = {Revolutions and Revelations in Computability: 18th Conference on Computability in Europe, CiE 2022, Swansea, UK, July 11–15, 2022, Proceedings},
  author = {U Berger, JNY Franklin, F Manea, A Pauly},
  journal = {2022},
  publisher = {books.google.com},
  abstract = {… With the advent of the "golden age of Natural Language Processing" [1] (NLP), a contagious 
enthusiasm on the capabilities of large language models (LLMs) started spreading from …},
  url = {https://books.google.com/books?hl=en&lr=&id=O0p3EAAAQBAJ&oi=fnd&pg=PR5&dq=%22large+language+models%22+%22mathematical+reasoning%22&ots=Wk0RIksrfu&sig=ByXJgafsVztou-dy-AjwMxo7QK0},
  note = {Retrieved from Google Scholar}
}

@article{MechanismUnknown,
  title = {Mechanism of feature learning in deep fully connected networks and kernel machines that recursively learn features},
  author = {A Radhakrishnan, D Beaglehole, P Pandit…},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {arxiv.org},
  abstract = {… average gradient outer product as an alternative to backpropagation could reduce the sizeable 
training costs associated with stateof-the-art models, including large language models for …},
  url = {https://arxiv.org/abs/2212.13881},
  note = {Retrieved from Google Scholar}
}

@article{EvaluatingUnknownc,
  title = {Evaluating tools for characterizing anterior urethral stricture disease: a comparison of the LSE system and the urethral stricture score},
  author = {JT Kurtzman, R Kosber, P Kerr…},
  journal = {The Journal of …, 2022},
  publisher = {auajournals.org},
  abstract = {… , including deep learning, machine learning and large language models and generative AI. 
… Like the U-Score, point allocation was not based on discrete mathematical reasoning, which …},
  url = {https://www.auajournals.org/doi/abs/10.1097/JU.0000000000002880},
  note = {Retrieved from Google Scholar}
}

% Total entries: 205