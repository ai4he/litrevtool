% BibTeX entries generated by LitRevTool
% ======================================================================

@article{WhatUnknown,
  title = {What do large language models learn beyond language?},
  author = {A Madasu, S Srivastava},
  journal = {arXiv preprint arXiv:2210.12302, 2022},
  publisher = {arxiv.org},
  abstract = {… Large language models (LMs) have rapidly become a mainstay in Natural Language Processing. … 
Further, previous methods explore mathematical reasoning tasks posed as language …},
  url = {https://arxiv.org/abs/2210.12302},
  note = {Retrieved from Google Scholar}
}

@article{LanguageUnknown,
  title = {Language models show human-like content effects on reasoning},
  author = {I Dasgupta, AK Lampinen, SCY Chan…},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {stanford.edu},
  abstract = {… More recently, large language models have been similarly shown to accurately predict 
neural representations in the human language system — large language models “predict nearly …},
  url = {http://web.stanford.edu/~jlmcc/papers/DasguptaLampinenEtAl22LMsShowHumanLikeContentEffectsInReasoning.pdf},
  note = {Retrieved from Google Scholar}
}

@article{StructuredUnknown,
  title = {Structured, flexible, and robust: benchmarking and improving large language models towards more human-like behavior in out-of-distribution reasoning tasks},
  author = {KM Collins, C Wong, J Feng, M Wei…},
  journal = {arXiv preprint arXiv …, 2022},
  publisher = {arxiv.org},
  abstract = {… Our results in Part I suggest that even very large language models may not capture the 
characteristic flexibility of human reasoning: they struggle to produce language reflecting novel …},
  url = {https://arxiv.org/abs/2205.05718},
  note = {Retrieved from Google Scholar}
}

% Total entries: 3